{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_KERAS=1\n",
      "\\\n"
     ]
    }
   ],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "\n",
    "import sys\n",
    "sys.path.append('..'+sep_local+'..')\n",
    "print(sep_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='pokemon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'C:\\\\Users\\\\Khalid\\\\Documents\\projects\\\\pokemon\\DS06\\\\'\n",
    "validation_percentage = 20\n",
    "valid_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Khalid\\\\Documents\\\\projects\\\\Generatives\\\\Generative_Models'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from training.generators.file_image_generator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEBUG    | Looking for images in 'all'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | 809 file found\n"
     ]
    }
   ],
   "source": [
    "imgs_list = create_image_lists(\n",
    "    image_dir=images_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape= image_size=(200, 200, 3)\n",
    "batch_size = 32\n",
    "latents_dim = 32\n",
    "intermediate_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 738 training files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 71 validation files\n"
     ]
    }
   ],
   "source": [
    "training_generator, testing_generator = get_generators(\n",
    "    images_list=imgs_list, \n",
    "    image_dir=images_dir, \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size, \n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: training_generator, \n",
    "    output_types=tf.float32 ,\n",
    "    output_shapes=tf.TensorShape((batch_size, ) + image_size)\n",
    ")\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: testing_generator, \n",
    "    output_types=tf.float32 ,\n",
    "    output_shapes=tf.TensorShape((batch_size, ) + image_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data[0].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_instance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(inputs_shape, Iterable):\n",
    "    _outputs_shape = np.prod(inputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_outputs_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lays = [tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=latents_dim)]\n",
    "\n",
    "dec_lays = [tf.keras.layers.Dense(units=latents_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=_outputs_shape),\n",
    "            tf.keras.layers.Reshape(inputs_shape)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'ITAAEpsnr'\n",
    "experiments_dir='experiments'+sep_local+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonIAAEpsnr'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.adversarial_basic.generative_adversarial.autoencoders.AAE import AAE as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape=image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latents_dim,\n",
    "        'layers': enc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latents_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(experiments_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonIAAEpsnr\\\\var_save_dir'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exist(_restore)\n",
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to restore trained model, set filepath=_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistical.basic_adversarial_losses import \\\n",
    "    create_generative_discriminator_real_losses, \\\n",
    "    create_generative_discriminator_fake_losses, \\\n",
    "    create_generative_generator_fake_losses, \\\n",
    "\n",
    "generative_discriminator_losses = {\n",
    "    'generative_discriminator_real_outputs': create_generative_discriminator_real_losses,\n",
    "    'generative_discriminator_fake_outputs': create_generative_discriminator_fake_losses,\n",
    "    'generative_generator_fake_outputs': create_generative_generator_fake_losses,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inference\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200, 200, 16)      64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                20480032  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 20,480,224\n",
      "Trainable params: 20,480,160\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generative\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120000)            2040000   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200, 200, 3)       12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 200, 200, 3)       0         \n",
      "=================================================================\n",
      "Total params: 2,041,596\n",
      "Trainable params: 2,041,590\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    }
   ],
   "source": [
  "ae = AE( \n",
    "    name= model_name,\n",
    "    latents_dim=latents_dim,\n",
    "    batch_size=batch_size,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.quantitive_metrics.peak_signal_to_noise_ratio import prepare_psnr\n",
    "from statistical.losses_utilities import similarty_to_distance\n",
    "",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pokemonIAAEpsnr\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inference (Model)            (None, 32)                20480224  \n",
      "_________________________________________________________________\n",
      "generative (Model)           (None, 200, 200, 3)       2041596   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_x_logits (Tensor [(None, 200, 200, 3)]     0         \n",
      "=================================================================\n",
      "Total params: 22,521,820\n",
      "Trainable params: 22,521,750\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ae.compile(loss={'x_logits': similarity_to_distance(prepare_psnr([ae.batch_size]+ae.get_inputs_shape()))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonIAAEpsnr\\\\var_save_dir'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore,save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonIAAEpsnr\\\\csv_dir\\\\pokemonIAAEpsnr.csv'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir = os.path.join(experiments_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, ae.name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(experiments_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latents_shape=latents_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training traditional basicAE\n",
      "Train for 10 steps, validate for 10 steps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 31s - loss: 7.3825 - prepare_psnr(inputs_flat_shape): 7.3397 - prepare_ssim_multiscale(inputs_flat_shape): 0.0342 - sharp_diff: 7.311 - ETA: 14s - loss: 7.3511 - prepare_psnr(inputs_flat_shape): 7.3056 - prepare_ssim_multiscale(inputs_flat_shape): 0.0320 - sharp_diff: 7.192 - ETA: 8s - loss: 7.3185 - prepare_psnr(inputs_flat_shape): 7.2680 - prepare_ssim_multiscale(inputs_flat_shape): 0.0311 - sharp_diff: 7.114 - ETA: 5s - loss: 7.2827 - prepare_psnr(inputs_flat_shape): 7.2283 - prepare_ssim_multiscale(inputs_flat_shape): 0.0309 - sharp_diff: 7.07 - ETA: 4s - loss: 7.2614 - prepare_psnr(inputs_flat_shape): 7.2041 - prepare_ssim_multiscale(inputs_flat_shape): 0.0316 - sharp_diff: 7.02 - ETA: 2s - loss: 7.2539 - prepare_psnr(inputs_flat_shape): 7.1918 - prepare_ssim_multiscale(inputs_flat_shape): 0.0320 - sharp_diff: 6.98 - ETA: 1s - loss: 7.2365 - prepare_psnr(inputs_flat_shape): 7.1711 - prepare_ssim_multiscale(inputs_flat_shape): 0.0306 - sharp_diff: 6.89 - ETA: 1s - loss: 7.2381 - prepare_psnr(inputs_flat_shape): 7.1698 - prepare_ssim_multiscale(inputs_flat_shape): 0.0306 - sharp_diff: 6.85 - ETA: 0s - loss: 7.2278 - prepare_psnr(inputs_flat_shape): 7.1565 - prepare_ssim_multiscale(inputs_flat_shape): 0.0292 - sharp_diff: 6.74 - 7s 750ms/step - loss: 7.2183 - prepare_psnr(inputs_flat_shape): 7.1441 - prepare_ssim_multiscale(inputs_flat_shape): 0.0284 - sharp_diff: 6.6592 - val_loss: 7.5106 - val_psnr: 7.5059 - val_ssmi: 0.1296 - val_sharp_diff: 11.4406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 7.0770 - prepare_psnr(inputs_flat_shape): 6.9772 - prepare_ssim_multiscale(inputs_flat_shape): 0.0185 - sharp_diff: 5.87 - ETA: 1s - loss: 7.0058 - prepare_psnr(inputs_flat_shape): 6.9050 - prepare_ssim_multiscale(inputs_flat_shape): 0.0187 - sharp_diff: 5.84 - ETA: 1s - loss: 6.9851 - prepare_psnr(inputs_flat_shape): 6.8847 - prepare_ssim_multiscale(inputs_flat_shape): 0.0193 - sharp_diff: 5.89 - ETA: 0s - loss: 6.9857 - prepare_psnr(inputs_flat_shape): 6.8848 - prepare_ssim_multiscale(inputs_flat_shape): 0.0200 - sharp_diff: 5.90 - ETA: 0s - loss: 6.9532 - prepare_psnr(inputs_flat_shape): 6.8514 - prepare_ssim_multiscale(inputs_flat_shape): 0.0199 - sharp_diff: 5.92 - ETA: 0s - loss: 6.9501 - prepare_psnr(inputs_flat_shape): 6.8473 - prepare_ssim_multiscale(inputs_flat_shape): 0.0213 - sharp_diff: 5.90 - ETA: 0s - loss: 6.9270 - prepare_psnr(inputs_flat_shape): 6.8230 - prepare_ssim_multiscale(inputs_flat_shape): 0.0209 - sharp_diff: 5.85 - ETA: 0s - loss: 6.9254 - prepare_psnr(inputs_flat_shape): 6.8203 - prepare_ssim_multiscale(inputs_flat_shape): 0.0218 - sharp_diff: 5.88 - ETA: 0s - loss: 6.9233 - prepare_psnr(inputs_flat_shape): 6.8174 - prepare_ssim_multiscale(inputs_flat_shape): 0.0222 - sharp_diff: 5.89 - 3s 280ms/step - loss: 6.9161 - prepare_psnr(inputs_flat_shape): 6.8085 - prepare_ssim_multiscale(inputs_flat_shape): 0.0223 - sharp_diff: 5.8759 - val_loss: 7.4516 - val_psnr: 7.4397 - val_ssmi: 0.0971 - val_sharp_diff: 10.4788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 6.6904 - prepare_psnr(inputs_flat_shape): 6.5700 - prepare_ssim_multiscale(inputs_flat_shape): 0.0192 - sharp_diff: 5.48 - ETA: 1s - loss: 6.7392 - prepare_psnr(inputs_flat_shape): 6.6190 - prepare_ssim_multiscale(inputs_flat_shape): 0.0204 - sharp_diff: 5.62 - ETA: 1s - loss: 6.5724 - prepare_psnr(inputs_flat_shape): 6.4512 - prepare_ssim_multiscale(inputs_flat_shape): 0.0185 - sharp_diff: 5.42 - ETA: 0s - loss: 6.6236 - prepare_psnr(inputs_flat_shape): 6.5009 - prepare_ssim_multiscale(inputs_flat_shape): 0.0189 - sharp_diff: 5.48 - ETA: 0s - loss: 6.5775 - prepare_psnr(inputs_flat_shape): 6.4532 - prepare_ssim_multiscale(inputs_flat_shape): 0.0186 - sharp_diff: 5.48 - ETA: 0s - loss: 6.5719 - prepare_psnr(inputs_flat_shape): 6.4458 - prepare_ssim_multiscale(inputs_flat_shape): 0.0186 - sharp_diff: 5.47 - ETA: 0s - loss: 6.5928 - prepare_psnr(inputs_flat_shape): 6.4662 - prepare_ssim_multiscale(inputs_flat_shape): 0.0190 - sharp_diff: 5.50 - ETA: 0s - loss: 6.5757 - prepare_psnr(inputs_flat_shape): 6.4475 - prepare_ssim_multiscale(inputs_flat_shape): 0.0185 - sharp_diff: 5.48 - ETA: 0s - loss: 6.5702 - prepare_psnr(inputs_flat_shape): 6.4400 - prepare_ssim_multiscale(inputs_flat_shape): 0.0189 - sharp_diff: 5.50 - 3s 273ms/step - loss: 6.5456 - prepare_psnr(inputs_flat_shape): 6.4143 - prepare_ssim_multiscale(inputs_flat_shape): 0.0189 - sharp_diff: 5.5155 - val_loss: 7.3401 - val_psnr: 7.3230 - val_ssmi: 0.0873 - val_sharp_diff: 10.3230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 6.2838 - prepare_psnr(inputs_flat_shape): 6.1303 - prepare_ssim_multiscale(inputs_flat_shape): 0.0164 - sharp_diff: 5.28 - ETA: 1s - loss: 6.2808 - prepare_psnr(inputs_flat_shape): 6.1303 - prepare_ssim_multiscale(inputs_flat_shape): 0.0158 - sharp_diff: 5.34 - ETA: 1s - loss: 6.2907 - prepare_psnr(inputs_flat_shape): 6.1392 - prepare_ssim_multiscale(inputs_flat_shape): 0.0159 - sharp_diff: 5.41 - ETA: 0s - loss: 6.2433 - prepare_psnr(inputs_flat_shape): 6.0902 - prepare_ssim_multiscale(inputs_flat_shape): 0.0151 - sharp_diff: 5.40 - ETA: 0s - loss: 6.2231 - prepare_psnr(inputs_flat_shape): 6.0680 - prepare_ssim_multiscale(inputs_flat_shape): 0.0156 - sharp_diff: 5.43 - ETA: 0s - loss: 6.1893 - prepare_psnr(inputs_flat_shape): 6.0324 - prepare_ssim_multiscale(inputs_flat_shape): 0.0155 - sharp_diff: 5.45 - ETA: 0s - loss: 6.1911 - prepare_psnr(inputs_flat_shape): 6.0333 - prepare_ssim_multiscale(inputs_flat_shape): 0.0160 - sharp_diff: 5.46 - ETA: 0s - loss: 6.1703 - prepare_psnr(inputs_flat_shape): 6.0115 - prepare_ssim_multiscale(inputs_flat_shape): 0.0159 - sharp_diff: 5.45 - ETA: 0s - loss: 6.1555 - prepare_psnr(inputs_flat_shape): 5.9946 - prepare_ssim_multiscale(inputs_flat_shape): 0.0160 - sharp_diff: 5.46 - 3s 273ms/step - loss: 6.1454 - prepare_psnr(inputs_flat_shape): 5.9827 - prepare_ssim_multiscale(inputs_flat_shape): 0.0161 - sharp_diff: 5.4801 - val_loss: 7.3068 - val_psnr: 7.2840 - val_ssmi: 0.0950 - val_sharp_diff: 10.4673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 6.1364 - prepare_psnr(inputs_flat_shape): 5.9609 - prepare_ssim_multiscale(inputs_flat_shape): 0.0195 - sharp_diff: 5.88 - ETA: 1s - loss: 6.1062 - prepare_psnr(inputs_flat_shape): 5.9286 - prepare_ssim_multiscale(inputs_flat_shape): 0.0185 - sharp_diff: 5.74 - ETA: 1s - loss: 6.0665 - prepare_psnr(inputs_flat_shape): 5.8892 - prepare_ssim_multiscale(inputs_flat_shape): 0.0174 - sharp_diff: 5.68 - ETA: 0s - loss: 6.0152 - prepare_psnr(inputs_flat_shape): 5.8348 - prepare_ssim_multiscale(inputs_flat_shape): 0.0180 - sharp_diff: 5.71 - ETA: 0s - loss: 6.0196 - prepare_psnr(inputs_flat_shape): 5.8381 - prepare_ssim_multiscale(inputs_flat_shape): 0.0179 - sharp_diff: 5.69 - ETA: 0s - loss: 6.0078 - prepare_psnr(inputs_flat_shape): 5.8249 - prepare_ssim_multiscale(inputs_flat_shape): 0.0174 - sharp_diff: 5.68 - ETA: 0s - loss: 5.9998 - prepare_psnr(inputs_flat_shape): 5.8155 - prepare_ssim_multiscale(inputs_flat_shape): 0.0164 - sharp_diff: 5.63 - ETA: 0s - loss: 5.9792 - prepare_psnr(inputs_flat_shape): 5.7931 - prepare_ssim_multiscale(inputs_flat_shape): 0.0162 - sharp_diff: 5.61 - ETA: 0s - loss: 5.9633 - prepare_psnr(inputs_flat_shape): 5.7765 - prepare_ssim_multiscale(inputs_flat_shape): 0.0162 - sharp_diff: 5.63 - 3s 272ms/step - loss: 5.9404 - prepare_psnr(inputs_flat_shape): 5.7519 - prepare_ssim_multiscale(inputs_flat_shape): 0.0159 - sharp_diff: 5.6195 - val_loss: 7.3046 - val_psnr: 7.2805 - val_ssmi: 0.1043 - val_sharp_diff: 10.9446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 5.8483 - prepare_psnr(inputs_flat_shape): 5.6450 - prepare_ssim_multiscale(inputs_flat_shape): 0.0149 - sharp_diff: 5.56 - ETA: 1s - loss: 5.8191 - prepare_psnr(inputs_flat_shape): 5.6148 - prepare_ssim_multiscale(inputs_flat_shape): 0.0155 - sharp_diff: 5.62 - ETA: 1s - loss: 5.8349 - prepare_psnr(inputs_flat_shape): 5.6311 - prepare_ssim_multiscale(inputs_flat_shape): 0.0152 - sharp_diff: 5.65 - ETA: 0s - loss: 5.8222 - prepare_psnr(inputs_flat_shape): 5.6178 - prepare_ssim_multiscale(inputs_flat_shape): 0.0152 - sharp_diff: 5.68 - ETA: 0s - loss: 5.8211 - prepare_psnr(inputs_flat_shape): 5.6158 - prepare_ssim_multiscale(inputs_flat_shape): 0.0148 - sharp_diff: 5.69 - ETA: 0s - loss: 5.7922 - prepare_psnr(inputs_flat_shape): 5.5858 - prepare_ssim_multiscale(inputs_flat_shape): 0.0145 - sharp_diff: 5.67 - ETA: 0s - loss: 5.7770 - prepare_psnr(inputs_flat_shape): 5.5705 - prepare_ssim_multiscale(inputs_flat_shape): 0.0145 - sharp_diff: 5.68 - ETA: 0s - loss: 5.7635 - prepare_psnr(inputs_flat_shape): 5.5560 - prepare_ssim_multiscale(inputs_flat_shape): 0.0143 - sharp_diff: 5.70 - ETA: 0s - loss: 5.7674 - prepare_psnr(inputs_flat_shape): 5.5588 - prepare_ssim_multiscale(inputs_flat_shape): 0.0142 - sharp_diff: 5.70 - 3s 343ms/step - loss: 5.7671 - prepare_psnr(inputs_flat_shape): 5.5584 - prepare_ssim_multiscale(inputs_flat_shape): 0.0141 - sharp_diff: 5.7022 - val_loss: 7.3422 - val_psnr: 7.3201 - val_ssmi: 0.1286 - val_sharp_diff: 11.3171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 5.6815 - prepare_psnr(inputs_flat_shape): 5.4628 - prepare_ssim_multiscale(inputs_flat_shape): 0.0167 - sharp_diff: 5.83 - ETA: 1s - loss: 5.6823 - prepare_psnr(inputs_flat_shape): 5.4671 - prepare_ssim_multiscale(inputs_flat_shape): 0.0152 - sharp_diff: 5.77 - ETA: 1s - loss: 5.6348 - prepare_psnr(inputs_flat_shape): 5.4181 - prepare_ssim_multiscale(inputs_flat_shape): 0.0147 - sharp_diff: 5.79 - ETA: 0s - loss: 5.6410 - prepare_psnr(inputs_flat_shape): 5.4238 - prepare_ssim_multiscale(inputs_flat_shape): 0.0150 - sharp_diff: 5.80 - ETA: 0s - loss: 5.6665 - prepare_psnr(inputs_flat_shape): 5.4500 - prepare_ssim_multiscale(inputs_flat_shape): 0.0148 - sharp_diff: 5.84 - ETA: 0s - loss: 5.6803 - prepare_psnr(inputs_flat_shape): 5.4635 - prepare_ssim_multiscale(inputs_flat_shape): 0.0154 - sharp_diff: 5.86 - ETA: 0s - loss: 5.6601 - prepare_psnr(inputs_flat_shape): 5.4426 - prepare_ssim_multiscale(inputs_flat_shape): 0.0153 - sharp_diff: 5.86 - ETA: 0s - loss: 5.6493 - prepare_psnr(inputs_flat_shape): 5.4304 - prepare_ssim_multiscale(inputs_flat_shape): 0.0151 - sharp_diff: 5.86 - ETA: 0s - loss: 5.6623 - prepare_psnr(inputs_flat_shape): 5.4430 - prepare_ssim_multiscale(inputs_flat_shape): 0.0154 - sharp_diff: 5.89 - 3s 278ms/step - loss: 5.6550 - prepare_psnr(inputs_flat_shape): 5.4349 - prepare_ssim_multiscale(inputs_flat_shape): 0.0154 - sharp_diff: 5.8984 - val_loss: 7.2479 - val_psnr: 7.2242 - val_ssmi: 0.1206 - val_sharp_diff: 11.3231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 5.4415 - prepare_psnr(inputs_flat_shape): 5.2148 - prepare_ssim_multiscale(inputs_flat_shape): 0.0097 - sharp_diff: 5.80 - ETA: 1s - loss: 5.5125 - prepare_psnr(inputs_flat_shape): 5.2865 - prepare_ssim_multiscale(inputs_flat_shape): 0.0119 - sharp_diff: 5.92 - ETA: 1s - loss: 5.4609 - prepare_psnr(inputs_flat_shape): 5.2327 - prepare_ssim_multiscale(inputs_flat_shape): 0.0114 - sharp_diff: 5.86 - ETA: 0s - loss: 5.5471 - prepare_psnr(inputs_flat_shape): 5.3201 - prepare_ssim_multiscale(inputs_flat_shape): 0.0122 - sharp_diff: 5.89 - ETA: 0s - loss: 5.5183 - prepare_psnr(inputs_flat_shape): 5.2905 - prepare_ssim_multiscale(inputs_flat_shape): 0.0121 - sharp_diff: 5.88 - ETA: 0s - loss: 5.5244 - prepare_psnr(inputs_flat_shape): 5.2961 - prepare_ssim_multiscale(inputs_flat_shape): 0.0123 - sharp_diff: 5.87 - ETA: 0s - loss: 5.5245 - prepare_psnr(inputs_flat_shape): 5.2961 - prepare_ssim_multiscale(inputs_flat_shape): 0.0125 - sharp_diff: 5.89 - ETA: 0s - loss: 5.5339 - prepare_psnr(inputs_flat_shape): 5.3053 - prepare_ssim_multiscale(inputs_flat_shape): 0.0125 - sharp_diff: 5.89 - ETA: 0s - loss: 5.5455 - prepare_psnr(inputs_flat_shape): 5.3167 - prepare_ssim_multiscale(inputs_flat_shape): 0.0128 - sharp_diff: 5.91 - 3s 266ms/step - loss: 5.5550 - prepare_psnr(inputs_flat_shape): 5.3262 - prepare_ssim_multiscale(inputs_flat_shape): 0.0131 - sharp_diff: 5.9229 - val_loss: 7.2870 - val_psnr: 7.2683 - val_ssmi: 0.1332 - val_sharp_diff: 11.7289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 5.5413 - prepare_psnr(inputs_flat_shape): 5.3081 - prepare_ssim_multiscale(inputs_flat_shape): 0.0116 - sharp_diff: 5.97 - ETA: 1s - loss: 5.5478 - prepare_psnr(inputs_flat_shape): 5.3140 - prepare_ssim_multiscale(inputs_flat_shape): 0.0134 - sharp_diff: 6.01 - ETA: 1s - loss: 5.4984 - prepare_psnr(inputs_flat_shape): 5.2649 - prepare_ssim_multiscale(inputs_flat_shape): 0.0134 - sharp_diff: 6.00 - ETA: 0s - loss: 5.5037 - prepare_psnr(inputs_flat_shape): 5.2698 - prepare_ssim_multiscale(inputs_flat_shape): 0.0133 - sharp_diff: 6.00 - ETA: 0s - loss: 5.4864 - prepare_psnr(inputs_flat_shape): 5.2522 - prepare_ssim_multiscale(inputs_flat_shape): 0.0137 - sharp_diff: 5.98 - ETA: 0s - loss: 5.4866 - prepare_psnr(inputs_flat_shape): 5.2514 - prepare_ssim_multiscale(inputs_flat_shape): 0.0133 - sharp_diff: 5.97 - ETA: 0s - loss: 5.4896 - prepare_psnr(inputs_flat_shape): 5.2540 - prepare_ssim_multiscale(inputs_flat_shape): 0.0135 - sharp_diff: 5.98 - ETA: 0s - loss: 5.4799 - prepare_psnr(inputs_flat_shape): 5.2438 - prepare_ssim_multiscale(inputs_flat_shape): 0.0133 - sharp_diff: 6.00 - ETA: 0s - loss: 5.4883 - prepare_psnr(inputs_flat_shape): 5.2521 - prepare_ssim_multiscale(inputs_flat_shape): 0.0135 - sharp_diff: 6.01 - 3s 272ms/step - loss: 5.4773 - prepare_psnr(inputs_flat_shape): 5.2407 - prepare_ssim_multiscale(inputs_flat_shape): 0.0134 - sharp_diff: 6.0214 - val_loss: 7.1140 - val_psnr: 7.0815 - val_ssmi: 0.1220 - val_sharp_diff: 11.5391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 1s - loss: 5.5068 - prepare_psnr(inputs_flat_shape): 5.2650 - prepare_ssim_multiscale(inputs_flat_shape): 0.0142 - sharp_diff: 6.06 - ETA: 1s - loss: 5.4824 - prepare_psnr(inputs_flat_shape): 5.2411 - prepare_ssim_multiscale(inputs_flat_shape): 0.0141 - sharp_diff: 6.11 - ETA: 1s - loss: 5.4873 - prepare_psnr(inputs_flat_shape): 5.2457 - prepare_ssim_multiscale(inputs_flat_shape): 0.0139 - sharp_diff: 6.13 - ETA: 0s - loss: 5.5137 - prepare_psnr(inputs_flat_shape): 5.2724 - prepare_ssim_multiscale(inputs_flat_shape): 0.0147 - sharp_diff: 6.11 - ETA: 0s - loss: 5.5502 - prepare_psnr(inputs_flat_shape): 5.3141 - prepare_ssim_multiscale(inputs_flat_shape): 0.0172 - sharp_diff: 6.10 - ETA: 0s - loss: 5.5386 - prepare_psnr(inputs_flat_shape): 5.3013 - prepare_ssim_multiscale(inputs_flat_shape): 0.0163 - sharp_diff: 6.09 - ETA: 0s - loss: 5.5278 - prepare_psnr(inputs_flat_shape): 5.2894 - prepare_ssim_multiscale(inputs_flat_shape): 0.0160 - sharp_diff: 6.08 - ETA: 0s - loss: 5.5191 - prepare_psnr(inputs_flat_shape): 5.2804 - prepare_ssim_multiscale(inputs_flat_shape): 0.0155 - sharp_diff: 6.09 - ETA: 0s - loss: 5.5063 - prepare_psnr(inputs_flat_shape): 5.2670 - prepare_ssim_multiscale(inputs_flat_shape): 0.0152 - sharp_diff: 6.09 - 3s 273ms/step - loss: 5.4988 - prepare_psnr(inputs_flat_shape): 5.2590 - prepare_ssim_multiscale(inputs_flat_shape): 0.0150 - sharp_diff: 6.0981 - val_loss: 7.0621 - val_psnr: 7.0204 - val_ssmi: 0.1219 - val_sharp_diff: 11.4837\n",
      "Model: \"generative_discriminator_real\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200, 200, 16)      64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                20480032  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "generative_discriminator_real_ou (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 20,480,257\n",
      "Trainable params: 20,480,193\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"generative_discriminator_fake\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200, 200, 16)      64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                20480032  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "generative_discriminator_fake_ou (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 20,480,257\n",
      "Trainable params: 20,480,193\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "training inputs real discriminator\n",
      "xxx Tensor(\"truediv:0\", shape=(32, 200, 200, 3), dtype=float32)\n",
      "xxx Tensor(\"truediv:0\", shape=(32, 200, 200, 3), dtype=float32)\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 11s - loss: 0.41 - ETA: 5s - loss: 0.5960 - ETA: 3s - loss: 0.603 - ETA: 2s - loss: 0.572 - ETA: 1s - loss: 0.555 - ETA: 1s - loss: 0.529 - ETA: 0s - loss: 0.527 - ETA: 0s - loss: 0.515 - ETA: 0s - loss: 0.503 - 4s 351ms/step - loss: 0.5062 - val_loss: 1.3356\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.414 - ETA: 0s - loss: 0.428 - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.432 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.398 - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.404 - ETA: 0s - loss: 0.415 - 2s 204ms/step - loss: 0.4108 - val_loss: 0.9158\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.447 - ETA: 0s - loss: 0.386 - ETA: 0s - loss: 0.403 - ETA: 0s - loss: 0.416 - ETA: 0s - loss: 0.423 - ETA: 0s - loss: 0.424 - ETA: 0s - loss: 0.424 - ETA: 0s - loss: 0.418 - ETA: 0s - loss: 0.413 - 2s 202ms/step - loss: 0.4153 - val_loss: 0.5317\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.290 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.358 - ETA: 0s - loss: 0.370 - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.369 - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.357 - 2s 199ms/step - loss: 0.3623 - val_loss: 0.4462\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.394 - ETA: 0s - loss: 0.372 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.354 - ETA: 0s - loss: 0.356 - ETA: 0s - loss: 0.360 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.359 - 2s 199ms/step - loss: 0.3607 - val_loss: 0.3754\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.346 - ETA: 0s - loss: 0.353 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.359 - ETA: 0s - loss: 0.377 - ETA: 0s - loss: 0.367 - ETA: 0s - loss: 0.357 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.356 - 2s 203ms/step - loss: 0.3543 - val_loss: 0.3387\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.257 - ETA: 0s - loss: 0.298 - ETA: 0s - loss: 0.318 - ETA: 0s - loss: 0.317 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.324 - ETA: 0s - loss: 0.328 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.320 - 2s 204ms/step - loss: 0.3273 - val_loss: 0.2400\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.344 - ETA: 0s - loss: 0.323 - ETA: 0s - loss: 0.331 - ETA: 0s - loss: 0.333 - ETA: 0s - loss: 0.347 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.336 - ETA: 0s - loss: 0.339 - ETA: 0s - loss: 0.335 - 2s 201ms/step - loss: 0.3413 - val_loss: 0.2258\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.301 - ETA: 0s - loss: 0.299 - ETA: 0s - loss: 0.304 - ETA: 0s - loss: 0.317 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.306 - ETA: 0s - loss: 0.305 - ETA: 0s - loss: 0.305 - ETA: 0s - loss: 0.306 - 2s 206ms/step - loss: 0.3074 - val_loss: 0.1825\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.278 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.305 - ETA: 0s - loss: 0.316 - ETA: 0s - loss: 0.315 - ETA: 0s - loss: 0.309 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.316 - 2s 200ms/step - loss: 0.3156 - val_loss: 0.2051\n",
      "\n",
      "training inputs fake discriminator\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - ETA: 13s - loss: 0.40 - ETA: 6s - loss: 0.5841 - ETA: 3s - loss: 0.609 - ETA: 2s - loss: 0.586 - ETA: 1s - loss: 0.569 - ETA: 1s - loss: 0.556 - ETA: 0s - loss: 0.544 - ETA: 0s - loss: 0.537 - ETA: 0s - loss: 0.526 - 4s 382ms/step - loss: 0.5175 - val_loss: 7.3630\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.422 - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.422 - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.436 - ETA: 0s - loss: 0.430 - ETA: 0s - loss: 0.421 - ETA: 0s - loss: 0.417 - 2s 203ms/step - loss: 0.4172 - val_loss: 3.8543\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.342 - ETA: 0s - loss: 0.351 - ETA: 0s - loss: 0.356 - ETA: 0s - loss: 0.360 - ETA: 0s - loss: 0.352 - ETA: 0s - loss: 0.359 - ETA: 0s - loss: 0.362 - ETA: 0s - loss: 0.363 - ETA: 0s - loss: 0.359 - 2s 202ms/step - loss: 0.3597 - val_loss: 2.5916\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.365 - ETA: 0s - loss: 0.375 - ETA: 0s - loss: 0.364 - ETA: 0s - loss: 0.354 - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.353 - ETA: 0s - loss: 0.350 - ETA: 0s - loss: 0.345 - ETA: 0s - loss: 0.340 - 2s 200ms/step - loss: 0.3393 - val_loss: 2.0296\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.325 - ETA: 0s - loss: 0.330 - ETA: 0s - loss: 0.330 - ETA: 0s - loss: 0.319 - ETA: 0s - loss: 0.322 - ETA: 0s - loss: 0.327 - ETA: 0s - loss: 0.326 - ETA: 0s - loss: 0.327 - ETA: 0s - loss: 0.325 - 2s 201ms/step - loss: 0.3234 - val_loss: 1.6262\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.317 - ETA: 0s - loss: 0.316 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.313 - ETA: 0s - loss: 0.314 - ETA: 0s - loss: 0.310 - ETA: 0s - loss: 0.311 - ETA: 0s - loss: 0.308 - ETA: 0s - loss: 0.308 - 2s 199ms/step - loss: 0.3056 - val_loss: 1.4049\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.272 - ETA: 0s - loss: 0.293 - ETA: 0s - loss: 0.297 - ETA: 0s - loss: 0.291 - ETA: 0s - loss: 0.295 - ETA: 0s - loss: 0.296 - ETA: 0s - loss: 0.294 - ETA: 0s - loss: 0.292 - ETA: 0s - loss: 0.289 - 2s 201ms/step - loss: 0.2885 - val_loss: 1.2225\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.278 - ETA: 0s - loss: 0.277 - ETA: 0s - loss: 0.276 - ETA: 0s - loss: 0.277 - ETA: 0s - loss: 0.276 - ETA: 0s - loss: 0.276 - 2s 204ms/step - loss: 0.2763 - val_loss: 1.0198\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.264 - ETA: 0s - loss: 0.261 - ETA: 0s - loss: 0.259 - ETA: 0s - loss: 0.253 - ETA: 0s - loss: 0.250 - ETA: 0s - loss: 0.255 - ETA: 0s - loss: 0.252 - ETA: 0s - loss: 0.254 - ETA: 0s - loss: 0.257 - 2s 199ms/step - loss: 0.2587 - val_loss: 0.8851\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.263 - ETA: 0s - loss: 0.268 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.274 - ETA: 0s - loss: 0.271 - ETA: 0s - loss: 0.266 - ETA: 0s - loss: 0.266 - ETA: 0s - loss: 0.265 - ETA: 0s - loss: 0.264 - 2s 199ms/step - loss: 0.2623 - val_loss: 0.7979\n",
      "Model: \"inputs_AA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inference_inputs (InputLayer)   [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(4,)]               0           inference_inputs[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal/Rando [(None, 200, 200, 3) 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal/mul ( [(None, 200, 200, 3) 0           tf_op_layer_random_normal/RandomS\n",
      "__________________________________________________________________________________________________\n",
      "inference (Model)               (None, 32)           20480224    inference_inputs[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_random_normal (Tens [(None, 200, 200, 3) 0           tf_op_layer_random_normal/mul[0][\n",
      "__________________________________________________________________________________________________\n",
      "generative (Model)              (None, 200, 200, 3)  2041596     inference[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "generative_discriminator_fake (Mode (None, 1)            20480257    inference_inputs[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "generative_discriminator_real (Mode (None, 1)            20480257    tf_op_layer_random_normal[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_x_logits_1 (TensorF [(None, 200, 200, 3) 0           generative[2][0]                 \n",
      "==================================================================================================\n",
      "Total params: 63,482,334\n",
      "Trainable params: 63,482,136\n",
      "Non-trainable params: 198\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "training together\n",
      "Train for 10 steps, validate for 10 steps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/10 [==========================>...] - ETA: 35s - loss: 87961.8984 - generative_discriminator_fake_outputs_loss: 0.2342 - generative_discriminator_fake_outputs_loss: 0.5611 - x_logits_loss: 87960.9141 - x_logits_psnr: 5.7167 - x_logits_ssmi: 0.0198 - x_logits_sharp_diff: 6.70 - ETA: 17s - loss: 81532.0117 - generative_discriminator_fake_outputs_loss: 0.2391 - generative_discriminator_fake_outputs_loss: 0.5091 - x_logits_loss: 81531.0938 - x_logits_psnr: 5.9897 - x_logits_ssmi: 0.0223 - x_logits_sharp_diff: 6.80 - ETA: 10s - loss: 79390.5208 - generative_discriminator_fake_outputs_loss: 0.2431 - generative_discriminator_fake_outputs_loss: 0.5315 - x_logits_loss: 79389.5859 - x_logits_psnr: 6.1765 - x_logits_ssmi: 0.0242 - x_logits_sharp_diff: 6.97 - ETA: 7s - loss: 77940.2227 - generative_discriminator_fake_outputs_loss: 0.2411 - generative_discriminator_fake_outputs_loss: 0.5156 - x_logits_loss: 77939.3125 - x_logits_psnr: 6.2604 - x_logits_ssmi: 0.0248 - x_logits_sharp_diff: 6.9878 - ETA: 5s - loss: 76453.6234 - generative_discriminator_fake_outputs_loss: 0.2399 - generative_discriminator_fake_outputs_loss: 0.5109 - x_logits_loss: 76452.7266 - x_logits_psnr: 6.3721 - x_logits_ssmi: 0.0254 - x_logits_sharp_diff: 7.021 - ETA: 3s - loss: 74697.7656 - generative_discriminator_fake_outputs_loss: 0.2390 - generative_discriminator_fake_outputs_loss: 0.4976 - x_logits_loss: 74696.8828 - x_logits_psnr: 6.4937 - x_logits_ssmi: 0.0269 - x_logits_sharp_diff: 7.076 - ETA: 2s - loss: 73095.6853 - generative_discriminator_fake_outputs_loss: 0.2395 - generative_discriminator_fake_outputs_loss: 0.5037 - x_logits_loss: 73094.8047 - x_logits_psnr: 6.5961 - x_logits_ssmi: 0.0274 - x_logits_sharp_diff: 7.077 - ETA: 1s - loss: 71273.1460 - generative_discriminator_fake_outputs_loss: 0.2397 - generative_discriminator_fake_outputs_loss: 0.5019 - x_logits_loss: 71272.2734 - x_logits_psnr: 6.7169 - x_logits_ssmi: 0.0282 - x_logits_sharp_diff: 7.125 - ETA: 0s - loss: 69771.8776 - generative_discriminator_fake_outputs_loss: 0.2391 - generative_discriminator_fake_outputs_loss: 0.4968 - x_logits_loss: 69771.0156 - x_logits_psnr: 6.8215 - x_logits_ssmi: 0.0291 - x_logits_sharp_diff: 7.1402INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAA44D9348>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAB5CE26C8>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAA44D9348>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAB5CE26C8>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: experiments\\pokemonIAAEpsnr\\var_save_dir\\assets\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAA44D9348>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAB5CE26C8>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "10/10 [==============================] - 23s 2s/step - loss: 68423.3449 - generative_discriminator_fake_outputs_loss: 0.2386 - generative_discriminator_fake_outputs_loss: 0.4975 - x_logits_loss: 68422.4844 - x_logits_psnr: 6.9162 - x_logits_ssmi: 0.0295 - x_logits_sharp_diff: 7.1318 - val_loss: 60260.3391 - val_generative_discriminator_fake_outputs_loss: 0.7104 - val_generative_discriminator_fake_outputs_loss: 7.7322 - val_x_logits_loss: 60251.8555 - val_x_logits_psnr: 7.2990 - val_x_logits_ssmi: 0.0857 - val_x_logits_sharp_diff: 10.0608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 3s - loss: 55294.2070 - generative_discriminator_fake_outputs_loss: 0.2178 - generative_discriminator_fake_outputs_loss: 0.5336 - x_logits_loss: 55293.3594 - x_logits_psnr: 7.8600 - x_logits_ssmi: 0.0378 - x_logits_sharp_diff: 7.411 - ETA: 2s - loss: 56199.8750 - generative_discriminator_fake_outputs_loss: 0.2256 - generative_discriminator_fake_outputs_loss: 0.5423 - x_logits_loss: 56199.0039 - x_logits_psnr: 7.8070 - x_logits_ssmi: 0.0358 - x_logits_sharp_diff: 7.465 - ETA: 2s - loss: 54730.3971 - generative_discriminator_fake_outputs_loss: 0.2250 - generative_discriminator_fake_outputs_loss: 0.5343 - x_logits_loss: 54729.5312 - x_logits_psnr: 7.9370 - x_logits_ssmi: 0.0378 - x_logits_sharp_diff: 7.554 - ETA: 1s - loss: 54047.3945 - generative_discriminator_fake_outputs_loss: 0.2290 - generative_discriminator_fake_outputs_loss: 0.5149 - x_logits_loss: 54046.5391 - x_logits_psnr: 8.0101 - x_logits_ssmi: 0.0380 - x_logits_sharp_diff: 7.565 - ETA: 1s - loss: 54004.4906 - generative_discriminator_fake_outputs_loss: 0.2305 - generative_discriminator_fake_outputs_loss: 0.4936 - x_logits_loss: 54003.6484 - x_logits_psnr: 8.0213 - x_logits_ssmi: 0.0376 - x_logits_sharp_diff: 7.525 - ETA: 1s - loss: 53523.1719 - generative_discriminator_fake_outputs_loss: 0.2313 - generative_discriminator_fake_outputs_loss: 0.4937 - x_logits_loss: 53522.3281 - x_logits_psnr: 8.0711 - x_logits_ssmi: 0.0386 - x_logits_sharp_diff: 7.550 - ETA: 0s - loss: 53212.9029 - generative_discriminator_fake_outputs_loss: 0.2304 - generative_discriminator_fake_outputs_loss: 0.4924 - x_logits_loss: 53212.0625 - x_logits_psnr: 8.1014 - x_logits_ssmi: 0.0389 - x_logits_sharp_diff: 7.546 - ETA: 0s - loss: 52717.7842 - generative_discriminator_fake_outputs_loss: 0.2297 - generative_discriminator_fake_outputs_loss: 0.5046 - x_logits_loss: 52716.9297 - x_logits_psnr: 8.1522 - x_logits_ssmi: 0.0398 - x_logits_sharp_diff: 7.525 - ETA: 0s - loss: 53073.4141 - generative_discriminator_fake_outputs_loss: 0.2282 - generative_discriminator_fake_outputs_loss: 0.5014 - x_logits_loss: 53072.5625 - x_logits_psnr: 8.1242 - x_logits_ssmi: 0.0383 - x_logits_sharp_diff: 7.496 - 5s 528ms/step - loss: 53001.8645 - generative_discriminator_fake_outputs_loss: 0.2279 - generative_discriminator_fake_outputs_loss: 0.5079 - x_logits_loss: 53001.0078 - x_logits_psnr: 8.1339 - x_logits_ssmi: 0.0378 - x_logits_sharp_diff: 7.4672 - val_loss: 57232.2383 - val_generative_discriminator_fake_outputs_loss: 0.6516 - val_generative_discriminator_fake_outputs_loss: 5.2884 - val_x_logits_loss: 57226.2383 - val_x_logits_psnr: 7.5917 - val_x_logits_ssmi: 0.1277 - val_x_logits_sharp_diff: 11.2152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 2s - loss: 49753.8516 - generative_discriminator_fake_outputs_loss: 0.2396 - generative_discriminator_fake_outputs_loss: 0.5210 - x_logits_loss: 49752.9453 - x_logits_psnr: 8.4860 - x_logits_ssmi: 0.0434 - x_logits_sharp_diff: 7.546 - ETA: 2s - loss: 50292.9824 - generative_discriminator_fake_outputs_loss: 0.2277 - generative_discriminator_fake_outputs_loss: 0.4645 - x_logits_loss: 50292.1406 - x_logits_psnr: 8.3969 - x_logits_ssmi: 0.0392 - x_logits_sharp_diff: 7.368 - ETA: 2s - loss: 47749.9727 - generative_discriminator_fake_outputs_loss: 0.2258 - generative_discriminator_fake_outputs_loss: 0.4670 - x_logits_loss: 47749.1250 - x_logits_psnr: 8.6519 - x_logits_ssmi: 0.0390 - x_logits_sharp_diff: 7.253 - ETA: 1s - loss: 47998.7734 - generative_discriminator_fake_outputs_loss: 0.2185 - generative_discriminator_fake_outputs_loss: 0.4538 - x_logits_loss: 47997.9453 - x_logits_psnr: 8.6218 - x_logits_ssmi: 0.0387 - x_logits_sharp_diff: 7.237 - ETA: 1s - loss: 48458.5938 - generative_discriminator_fake_outputs_loss: 0.2177 - generative_discriminator_fake_outputs_loss: 0.4508 - x_logits_loss: 48457.7695 - x_logits_psnr: 8.5813 - x_logits_ssmi: 0.0377 - x_logits_sharp_diff: 7.241 - ETA: 1s - loss: 49175.4570 - generative_discriminator_fake_outputs_loss: 0.2181 - generative_discriminator_fake_outputs_loss: 0.4413 - x_logits_loss: 49174.6406 - x_logits_psnr: 8.5145 - x_logits_ssmi: 0.0365 - x_logits_sharp_diff: 7.229 - ETA: 1s - loss: 49170.7461 - generative_discriminator_fake_outputs_loss: 0.2175 - generative_discriminator_fake_outputs_loss: 0.4378 - x_logits_loss: 49169.9336 - x_logits_psnr: 8.5154 - x_logits_ssmi: 0.0366 - x_logits_sharp_diff: 7.220 - ETA: 0s - loss: 49465.1328 - generative_discriminator_fake_outputs_loss: 0.2183 - generative_discriminator_fake_outputs_loss: 0.4404 - x_logits_loss: 49464.3164 - x_logits_psnr: 8.4908 - x_logits_ssmi: 0.0361 - x_logits_sharp_diff: 7.224 - ETA: 0s - loss: 49307.6910 - generative_discriminator_fake_outputs_loss: 0.2180 - generative_discriminator_fake_outputs_loss: 0.4344 - x_logits_loss: 49306.8828 - x_logits_psnr: 8.5035 - x_logits_ssmi: 0.0364 - x_logits_sharp_diff: 7.224 - 5s 547ms/step - loss: 49151.6480 - generative_discriminator_fake_outputs_loss: 0.2174 - generative_discriminator_fake_outputs_loss: 0.4336 - x_logits_loss: 49150.8359 - x_logits_psnr: 8.5175 - x_logits_ssmi: 0.0366 - x_logits_sharp_diff: 7.2204 - val_loss: 56740.0687 - val_generative_discriminator_fake_outputs_loss: 0.6007 - val_generative_discriminator_fake_outputs_loss: 4.1378 - val_x_logits_loss: 56735.2695 - val_x_logits_psnr: 7.6508 - val_x_logits_ssmi: 0.1267 - val_x_logits_sharp_diff: 11.4196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 3s - loss: 54207.9141 - generative_discriminator_fake_outputs_loss: 0.2137 - generative_discriminator_fake_outputs_loss: 0.3494 - x_logits_loss: 54207.1758 - x_logits_psnr: 8.1129 - x_logits_ssmi: 0.0300 - x_logits_sharp_diff: 7.266 - ETA: 2s - loss: 53363.1582 - generative_discriminator_fake_outputs_loss: 0.2235 - generative_discriminator_fake_outputs_loss: 0.3710 - x_logits_loss: 53362.3906 - x_logits_psnr: 8.1676 - x_logits_ssmi: 0.0334 - x_logits_sharp_diff: 7.332 - ETA: 2s - loss: 53292.6380 - generative_discriminator_fake_outputs_loss: 0.2275 - generative_discriminator_fake_outputs_loss: 0.3634 - x_logits_loss: 53291.8750 - x_logits_psnr: 8.1669 - x_logits_ssmi: 0.0329 - x_logits_sharp_diff: 7.295 - ETA: 2s - loss: 51778.4463 - generative_discriminator_fake_outputs_loss: 0.2212 - generative_discriminator_fake_outputs_loss: 0.3726 - x_logits_loss: 51777.6797 - x_logits_psnr: 8.3030 - x_logits_ssmi: 0.0338 - x_logits_sharp_diff: 7.260 - ETA: 1s - loss: 51193.4336 - generative_discriminator_fake_outputs_loss: 0.2177 - generative_discriminator_fake_outputs_loss: 0.3768 - x_logits_loss: 51192.6641 - x_logits_psnr: 8.3771 - x_logits_ssmi: 0.0356 - x_logits_sharp_diff: 7.281 - ETA: 1s - loss: 50189.1621 - generative_discriminator_fake_outputs_loss: 0.2158 - generative_discriminator_fake_outputs_loss: 0.3806 - x_logits_loss: 50188.3867 - x_logits_psnr: 8.4839 - x_logits_ssmi: 0.0374 - x_logits_sharp_diff: 7.267 - ETA: 1s - loss: 50280.4062 - generative_discriminator_fake_outputs_loss: 0.2169 - generative_discriminator_fake_outputs_loss: 0.3768 - x_logits_loss: 50279.6328 - x_logits_psnr: 8.4778 - x_logits_ssmi: 0.0368 - x_logits_sharp_diff: 7.257 - ETA: 0s - loss: 50252.5576 - generative_discriminator_fake_outputs_loss: 0.2169 - generative_discriminator_fake_outputs_loss: 0.3798 - x_logits_loss: 50251.7812 - x_logits_psnr: 8.4823 - x_logits_ssmi: 0.0361 - x_logits_sharp_diff: 7.232 - ETA: 0s - loss: 50353.2869 - generative_discriminator_fake_outputs_loss: 0.2168 - generative_discriminator_fake_outputs_loss: 0.3808 - x_logits_loss: 50352.5117 - x_logits_psnr: 8.4680 - x_logits_ssmi: 0.0354 - x_logits_sharp_diff: 7.215 - 6s 555ms/step - loss: 50173.4109 - generative_discriminator_fake_outputs_loss: 0.2145 - generative_discriminator_fake_outputs_loss: 0.3769 - x_logits_loss: 50172.6406 - x_logits_psnr: 8.4867 - x_logits_ssmi: 0.0356 - x_logits_sharp_diff: 7.2103 - val_loss: 56667.3508 - val_generative_discriminator_fake_outputs_loss: 0.5833 - val_generative_discriminator_fake_outputs_loss: 2.8332 - val_x_logits_loss: 56663.8867 - val_x_logits_psnr: 7.6609 - val_x_logits_ssmi: 0.1290 - val_x_logits_sharp_diff: 11.6706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 2s - loss: 44785.5703 - generative_discriminator_fake_outputs_loss: 0.2194 - generative_discriminator_fake_outputs_loss: 0.3575 - x_logits_loss: 44784.8125 - x_logits_psnr: 9.0027 - x_logits_ssmi: 0.0425 - x_logits_sharp_diff: 7.286 - ETA: 2s - loss: 47503.3145 - generative_discriminator_fake_outputs_loss: 0.2118 - generative_discriminator_fake_outputs_loss: 0.3488 - x_logits_loss: 47502.5703 - x_logits_psnr: 8.7499 - x_logits_ssmi: 0.0375 - x_logits_sharp_diff: 7.199 - ETA: 2s - loss: 48672.7734 - generative_discriminator_fake_outputs_loss: 0.2128 - generative_discriminator_fake_outputs_loss: 0.3492 - x_logits_loss: 48672.0312 - x_logits_psnr: 8.6390 - x_logits_ssmi: 0.0353 - x_logits_sharp_diff: 7.190 - ETA: 1s - loss: 49248.4277 - generative_discriminator_fake_outputs_loss: 0.2086 - generative_discriminator_fake_outputs_loss: 0.3605 - x_logits_loss: 49247.6797 - x_logits_psnr: 8.5839 - x_logits_ssmi: 0.0348 - x_logits_sharp_diff: 7.200 - ETA: 1s - loss: 48867.4938 - generative_discriminator_fake_outputs_loss: 0.2075 - generative_discriminator_fake_outputs_loss: 0.3570 - x_logits_loss: 48866.7500 - x_logits_psnr: 8.6199 - x_logits_ssmi: 0.0367 - x_logits_sharp_diff: 7.253 - ETA: 1s - loss: 49133.0775 - generative_discriminator_fake_outputs_loss: 0.2057 - generative_discriminator_fake_outputs_loss: 0.3515 - x_logits_loss: 49132.3438 - x_logits_psnr: 8.5893 - x_logits_ssmi: 0.0366 - x_logits_sharp_diff: 7.239 - ETA: 1s - loss: 49191.7098 - generative_discriminator_fake_outputs_loss: 0.2061 - generative_discriminator_fake_outputs_loss: 0.3474 - x_logits_loss: 49190.9766 - x_logits_psnr: 8.5791 - x_logits_ssmi: 0.0364 - x_logits_sharp_diff: 7.199 - ETA: 0s - loss: 49097.0791 - generative_discriminator_fake_outputs_loss: 0.2044 - generative_discriminator_fake_outputs_loss: 0.3446 - x_logits_loss: 49096.3516 - x_logits_psnr: 8.5933 - x_logits_ssmi: 0.0369 - x_logits_sharp_diff: 7.214 - ETA: 0s - loss: 49005.8481 - generative_discriminator_fake_outputs_loss: 0.2026 - generative_discriminator_fake_outputs_loss: 0.3431 - x_logits_loss: 49005.1250 - x_logits_psnr: 8.6030 - x_logits_ssmi: 0.0371 - x_logits_sharp_diff: 7.212 - 5s 543ms/step - loss: 49058.8863 - generative_discriminator_fake_outputs_loss: 0.2000 - generative_discriminator_fake_outputs_loss: 0.3437 - x_logits_loss: 49058.1641 - x_logits_psnr: 8.5963 - x_logits_ssmi: 0.0370 - x_logits_sharp_diff: 7.1987 - val_loss: 56359.4586 - val_generative_discriminator_fake_outputs_loss: 0.5448 - val_generative_discriminator_fake_outputs_loss: 2.0051 - val_x_logits_loss: 56356.8672 - val_x_logits_psnr: 7.6838 - val_x_logits_ssmi: 0.1321 - val_x_logits_sharp_diff: 11.7470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " 9/10 [==========================>...] - ETA: 2s - loss: 46819.0625 - generative_discriminator_fake_outputs_loss: 0.1976 - generative_discriminator_fake_outputs_loss: 0.3093 - x_logits_loss: 46818.3711 - x_logits_psnr: 8.7802 - x_logits_ssmi: 0.0428 - x_logits_sharp_diff: 7.198 - ETA: 2s - loss: 47113.2305 - generative_discriminator_fake_outputs_loss: 0.2005 - generative_discriminator_fake_outputs_loss: 0.3180 - x_logits_loss: 47112.5312 - x_logits_psnr: 8.7599 - x_logits_ssmi: 0.0408 - x_logits_sharp_diff: 7.262 - ETA: 2s - loss: 48355.9831 - generative_discriminator_fake_outputs_loss: 0.1963 - generative_discriminator_fake_outputs_loss: 0.3324 - x_logits_loss: 48355.2695 - x_logits_psnr: 8.6653 - x_logits_ssmi: 0.0386 - x_logits_sharp_diff: 7.284 - ETA: 1s - loss: 49150.8076 - generative_discriminator_fake_outputs_loss: 0.1916 - generative_discriminator_fake_outputs_loss: 0.3437 - x_logits_loss: 49150.0859 - x_logits_psnr: 8.5927 - x_logits_ssmi: 0.0372 - x_logits_sharp_diff: 7.298 - ETA: 1s - loss: 48870.7219 - generative_discriminator_fake_outputs_loss: 0.1920 - generative_discriminator_fake_outputs_loss: 0.3429 - x_logits_loss: 48870.0000 - x_logits_psnr: 8.6215 - x_logits_ssmi: 0.0375 - x_logits_sharp_diff: 7.285 - ETA: 1s - loss: 48471.5286 - generative_discriminator_fake_outputs_loss: 0.1911 - generative_discriminator_fake_outputs_loss: 0.3361 - x_logits_loss: 48470.8164 - x_logits_psnr: 8.6521 - x_logits_ssmi: 0.0380 - x_logits_sharp_diff: 7.273 - ETA: 0s - loss: 48171.7695 - generative_discriminator_fake_outputs_loss: 0.1902 - generative_discriminator_fake_outputs_loss: 0.3319 - x_logits_loss: 48171.0625 - x_logits_psnr: 8.6772 - x_logits_ssmi: 0.0384 - x_logits_sharp_diff: 7.269 - ETA: 0s - loss: 48302.9756 - generative_discriminator_fake_outputs_loss: 0.1904 - generative_discriminator_fake_outputs_loss: 0.3269 - x_logits_loss: 48302.2734 - x_logits_psnr: 8.6653 - x_logits_ssmi: 0.0381 - x_logits_sharp_diff: 7.255 - ETA: 0s - loss: 48270.9931 - generative_discriminator_fake_outputs_loss: 0.1891 - generative_discriminator_fake_outputs_loss: 0.3278 - x_logits_loss: 48270.2930 - x_logits_psnr: 8.6706 - x_logits_ssmi: 0.0382 - x_logits_sharp_diff: 7.2480INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAD28B5708>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAA44D9348>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAB5CE26C8>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAD28B5708>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAA44D9348>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAB5CE26C8>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Assets written to: experiments\\pokemonIAAEpsnr\\var_save_dir\\assets\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAD28B5708>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAA44D9348>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x000001EAB5CE26C8>, (200, 200, 3), [50, 32], TensorSpec(shape=(50, 32), dtype=tf.float32, name='eps')), {}).\n",
      "10/10 [==============================] - 21s 2s/step - loss: 48009.9258 - generative_discriminator_fake_outputs_loss: 0.1904 - generative_discriminator_fake_outputs_loss: 0.3232 - x_logits_loss: 48009.2266 - x_logits_psnr: 8.6992 - x_logits_ssmi: 0.0388 - x_logits_sharp_diff: 7.2579 - val_loss: 57001.0074 - val_generative_discriminator_fake_outputs_loss: 0.5086 - val_generative_discriminator_fake_outputs_loss: 1.6175 - val_x_logits_loss: 56998.8516 - val_x_logits_psnr: 7.6404 - val_x_logits_ssmi: 0.1289 - val_x_logits_sharp_diff: 11.9043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 3s - loss: 48206.1719 - generative_discriminator_fake_outputs_loss: 0.1850 - generative_discriminator_fake_outputs_loss: 0.3143 - x_logits_loss: 48205.4844 - x_logits_psnr: 8.6921 - x_logits_ssmi: 0.0396 - x_logits_sharp_diff: 7.356 - ETA: 2s - loss: 47353.4043 - generative_discriminator_fake_outputs_loss: 0.1894 - generative_discriminator_fake_outputs_loss: 0.3000 - x_logits_loss: 47352.7266 - x_logits_psnr: 8.7796 - x_logits_ssmi: 0.0407 - x_logits_sharp_diff: 7.284 - ETA: 2s - loss: 46717.9674 - generative_discriminator_fake_outputs_loss: 0.1859 - generative_discriminator_fake_outputs_loss: 0.2916 - x_logits_loss: 46717.3008 - x_logits_psnr: 8.8361 - x_logits_ssmi: 0.0419 - x_logits_sharp_diff: 7.275 - ETA: 2s - loss: 47609.2949 - generative_discriminator_fake_outputs_loss: 0.1835 - generative_discriminator_fake_outputs_loss: 0.2921 - x_logits_loss: 47608.6328 - x_logits_psnr: 8.7460 - x_logits_ssmi: 0.0396 - x_logits_sharp_diff: 7.267 - ETA: 1s - loss: 47941.5500 - generative_discriminator_fake_outputs_loss: 0.1811 - generative_discriminator_fake_outputs_loss: 0.2956 - x_logits_loss: 47940.8867 - x_logits_psnr: 8.7161 - x_logits_ssmi: 0.0384 - x_logits_sharp_diff: 7.228 - ETA: 1s - loss: 47865.4141 - generative_discriminator_fake_outputs_loss: 0.1810 - generative_discriminator_fake_outputs_loss: 0.2896 - x_logits_loss: 47864.7617 - x_logits_psnr: 8.7220 - x_logits_ssmi: 0.0391 - x_logits_sharp_diff: 7.256 - ETA: 0s - loss: 48347.3410 - generative_discriminator_fake_outputs_loss: 0.1811 - generative_discriminator_fake_outputs_loss: 0.2882 - x_logits_loss: 48346.6875 - x_logits_psnr: 8.6863 - x_logits_ssmi: 0.0386 - x_logits_sharp_diff: 7.264 - ETA: 0s - loss: 48535.4165 - generative_discriminator_fake_outputs_loss: 0.1821 - generative_discriminator_fake_outputs_loss: 0.2885 - x_logits_loss: 48534.7617 - x_logits_psnr: 8.6664 - x_logits_ssmi: 0.0384 - x_logits_sharp_diff: 7.271 - ETA: 0s - loss: 48086.1814 - generative_discriminator_fake_outputs_loss: 0.1831 - generative_discriminator_fake_outputs_loss: 0.2885 - x_logits_loss: 48085.5234 - x_logits_psnr: 8.7108 - x_logits_ssmi: 0.0391 - x_logits_sharp_diff: 7.266 - 5s 528ms/step - loss: 48081.9688 - generative_discriminator_fake_outputs_loss: 0.1835 - generative_discriminator_fake_outputs_loss: 0.2886 - x_logits_loss: 48081.3125 - x_logits_psnr: 8.7092 - x_logits_ssmi: 0.0395 - x_logits_sharp_diff: 7.2797 - val_loss: 55562.6477 - val_generative_discriminator_fake_outputs_loss: 0.4926 - val_generative_discriminator_fake_outputs_loss: 1.3302 - val_x_logits_loss: 55560.7930 - val_x_logits_psnr: 7.7665 - val_x_logits_ssmi: 0.1427 - val_x_logits_sharp_diff: 11.9795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 2s - loss: 60465.1445 - generative_discriminator_fake_outputs_loss: 0.1703 - generative_discriminator_fake_outputs_loss: 0.2840 - x_logits_loss: 60464.5078 - x_logits_psnr: 7.7133 - x_logits_ssmi: 0.0154 - x_logits_sharp_diff: 7.361 - ETA: 2s - loss: 54691.2754 - generative_discriminator_fake_outputs_loss: 0.1719 - generative_discriminator_fake_outputs_loss: 0.2782 - x_logits_loss: 54690.6406 - x_logits_psnr: 8.1655 - x_logits_ssmi: 0.0279 - x_logits_sharp_diff: 7.336 - ETA: 2s - loss: 53134.3477 - generative_discriminator_fake_outputs_loss: 0.1722 - generative_discriminator_fake_outputs_loss: 0.2841 - x_logits_loss: 53133.7070 - x_logits_psnr: 8.2979 - x_logits_ssmi: 0.0298 - x_logits_sharp_diff: 7.323 - ETA: 2s - loss: 51547.3516 - generative_discriminator_fake_outputs_loss: 0.1733 - generative_discriminator_fake_outputs_loss: 0.2833 - x_logits_loss: 51546.7109 - x_logits_psnr: 8.4366 - x_logits_ssmi: 0.0314 - x_logits_sharp_diff: 7.283 - ETA: 1s - loss: 50419.1359 - generative_discriminator_fake_outputs_loss: 0.1725 - generative_discriminator_fake_outputs_loss: 0.2845 - x_logits_loss: 50418.4922 - x_logits_psnr: 8.5316 - x_logits_ssmi: 0.0336 - x_logits_sharp_diff: 7.272 - ETA: 1s - loss: 49804.2116 - generative_discriminator_fake_outputs_loss: 0.1727 - generative_discriminator_fake_outputs_loss: 0.2839 - x_logits_loss: 49803.5664 - x_logits_psnr: 8.5868 - x_logits_ssmi: 0.0350 - x_logits_sharp_diff: 7.272 - ETA: 1s - loss: 49446.3231 - generative_discriminator_fake_outputs_loss: 0.1714 - generative_discriminator_fake_outputs_loss: 0.2838 - x_logits_loss: 49445.6797 - x_logits_psnr: 8.6219 - x_logits_ssmi: 0.0358 - x_logits_sharp_diff: 7.268 - ETA: 0s - loss: 49319.2007 - generative_discriminator_fake_outputs_loss: 0.1706 - generative_discriminator_fake_outputs_loss: 0.2790 - x_logits_loss: 49318.5625 - x_logits_psnr: 8.6277 - x_logits_ssmi: 0.0359 - x_logits_sharp_diff: 7.272 - ETA: 0s - loss: 49200.9761 - generative_discriminator_fake_outputs_loss: 0.1706 - generative_discriminator_fake_outputs_loss: 0.2783 - x_logits_loss: 49200.3398 - x_logits_psnr: 8.6327 - x_logits_ssmi: 0.0363 - x_logits_sharp_diff: 7.264 - 5s 524ms/step - loss: 49017.3637 - generative_discriminator_fake_outputs_loss: 0.1712 - generative_discriminator_fake_outputs_loss: 0.2759 - x_logits_loss: 49016.7305 - x_logits_psnr: 8.6455 - x_logits_ssmi: 0.0367 - x_logits_sharp_diff: 7.2620 - val_loss: 55877.4926 - val_generative_discriminator_fake_outputs_loss: 0.4619 - val_generative_discriminator_fake_outputs_loss: 0.9686 - val_x_logits_loss: 55876.0312 - val_x_logits_psnr: 7.7326 - val_x_logits_ssmi: 0.1343 - val_x_logits_sharp_diff: 11.9577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 3s - loss: 46452.2695 - generative_discriminator_fake_outputs_loss: 0.1797 - generative_discriminator_fake_outputs_loss: 0.2707 - x_logits_loss: 46451.6406 - x_logits_psnr: 8.8863 - x_logits_ssmi: 0.0398 - x_logits_sharp_diff: 7.238 - ETA: 2s - loss: 46484.1953 - generative_discriminator_fake_outputs_loss: 0.1720 - generative_discriminator_fake_outputs_loss: 0.2815 - x_logits_loss: 46483.5625 - x_logits_psnr: 8.8759 - x_logits_ssmi: 0.0405 - x_logits_sharp_diff: 7.200 - ETA: 2s - loss: 46769.5182 - generative_discriminator_fake_outputs_loss: 0.1684 - generative_discriminator_fake_outputs_loss: 0.2805 - x_logits_loss: 46768.8867 - x_logits_psnr: 8.8492 - x_logits_ssmi: 0.0416 - x_logits_sharp_diff: 7.215 - ETA: 2s - loss: 46978.4326 - generative_discriminator_fake_outputs_loss: 0.1671 - generative_discriminator_fake_outputs_loss: 0.2837 - x_logits_loss: 46977.7969 - x_logits_psnr: 8.8316 - x_logits_ssmi: 0.0421 - x_logits_sharp_diff: 7.245 - ETA: 1s - loss: 46595.1055 - generative_discriminator_fake_outputs_loss: 0.1668 - generative_discriminator_fake_outputs_loss: 0.2823 - x_logits_loss: 46594.4727 - x_logits_psnr: 8.8624 - x_logits_ssmi: 0.0426 - x_logits_sharp_diff: 7.240 - ETA: 1s - loss: 46336.1836 - generative_discriminator_fake_outputs_loss: 0.1650 - generative_discriminator_fake_outputs_loss: 0.2828 - x_logits_loss: 46335.5508 - x_logits_psnr: 8.8910 - x_logits_ssmi: 0.0428 - x_logits_sharp_diff: 7.253 - ETA: 1s - loss: 46758.2009 - generative_discriminator_fake_outputs_loss: 0.1663 - generative_discriminator_fake_outputs_loss: 0.2815 - x_logits_loss: 46757.5703 - x_logits_psnr: 8.8487 - x_logits_ssmi: 0.0415 - x_logits_sharp_diff: 7.251 - ETA: 0s - loss: 46803.5483 - generative_discriminator_fake_outputs_loss: 0.1668 - generative_discriminator_fake_outputs_loss: 0.2806 - x_logits_loss: 46802.9180 - x_logits_psnr: 8.8473 - x_logits_ssmi: 0.0412 - x_logits_sharp_diff: 7.236 - ETA: 0s - loss: 46798.7839 - generative_discriminator_fake_outputs_loss: 0.1663 - generative_discriminator_fake_outputs_loss: 0.2779 - x_logits_loss: 46798.1562 - x_logits_psnr: 8.8504 - x_logits_ssmi: 0.0406 - x_logits_sharp_diff: 7.236 - 6s 553ms/step - loss: 46533.2875 - generative_discriminator_fake_outputs_loss: 0.1667 - generative_discriminator_fake_outputs_loss: 0.2737 - x_logits_loss: 46532.6641 - x_logits_psnr: 8.8747 - x_logits_ssmi: 0.0411 - x_logits_sharp_diff: 7.2354 - val_loss: 55285.1055 - val_generative_discriminator_fake_outputs_loss: 0.4300 - val_generative_discriminator_fake_outputs_loss: 0.7626 - val_x_logits_loss: 55283.8867 - val_x_logits_psnr: 7.7995 - val_x_logits_ssmi: 0.1423 - val_x_logits_sharp_diff: 11.9884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=10, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 2s - loss: 47817.8438 - generative_discriminator_fake_outputs_loss: 0.1526 - generative_discriminator_fake_outputs_loss: 0.2315 - x_logits_loss: 47817.2734 - x_logits_psnr: 8.7202 - x_logits_ssmi: 0.0356 - x_logits_sharp_diff: 7.266 - ETA: 2s - loss: 48215.5410 - generative_discriminator_fake_outputs_loss: 0.1525 - generative_discriminator_fake_outputs_loss: 0.2420 - x_logits_loss: 48214.9609 - x_logits_psnr: 8.6872 - x_logits_ssmi: 0.0356 - x_logits_sharp_diff: 7.268 - ETA: 2s - loss: 48617.7161 - generative_discriminator_fake_outputs_loss: 0.1495 - generative_discriminator_fake_outputs_loss: 0.2431 - x_logits_loss: 48617.1367 - x_logits_psnr: 8.6563 - x_logits_ssmi: 0.0354 - x_logits_sharp_diff: 7.261 - ETA: 2s - loss: 47809.8584 - generative_discriminator_fake_outputs_loss: 0.1501 - generative_discriminator_fake_outputs_loss: 0.2504 - x_logits_loss: 47809.2695 - x_logits_psnr: 8.7409 - x_logits_ssmi: 0.0361 - x_logits_sharp_diff: 7.233 - ETA: 1s - loss: 46036.8617 - generative_discriminator_fake_outputs_loss: 0.1504 - generative_discriminator_fake_outputs_loss: 0.2553 - x_logits_loss: 46036.2656 - x_logits_psnr: 8.9032 - x_logits_ssmi: 0.0393 - x_logits_sharp_diff: 7.143 - ETA: 1s - loss: 46366.7441 - generative_discriminator_fake_outputs_loss: 0.1528 - generative_discriminator_fake_outputs_loss: 0.2542 - x_logits_loss: 46366.1445 - x_logits_psnr: 8.8757 - x_logits_ssmi: 0.0390 - x_logits_sharp_diff: 7.176 - ETA: 1s - loss: 46216.8504 - generative_discriminator_fake_outputs_loss: 0.1528 - generative_discriminator_fake_outputs_loss: 0.2542 - x_logits_loss: 46216.2539 - x_logits_psnr: 8.8913 - x_logits_ssmi: 0.0398 - x_logits_sharp_diff: 7.173 - ETA: 0s - loss: 45991.6157 - generative_discriminator_fake_outputs_loss: 0.1535 - generative_discriminator_fake_outputs_loss: 0.2560 - x_logits_loss: 45991.0156 - x_logits_psnr: 8.9180 - x_logits_ssmi: 0.0403 - x_logits_sharp_diff: 7.169 - ETA: 0s - loss: 46303.8025 - generative_discriminator_fake_outputs_loss: 0.1526 - generative_discriminator_fake_outputs_loss: 0.2538 - x_logits_loss: 46303.2031 - x_logits_psnr: 8.8900 - x_logits_ssmi: 0.0398 - x_logits_sharp_diff: 7.176 - 5s 546ms/step - loss: 46280.9227 - generative_discriminator_fake_outputs_loss: 0.1526 - generative_discriminator_fake_outputs_loss: 0.2537 - x_logits_loss: 46280.3242 - x_logits_psnr: 8.8947 - x_logits_ssmi: 0.0404 - x_logits_sharp_diff: 7.1902 - val_loss: 54391.6801 - val_generative_discriminator_fake_outputs_loss: 0.4062 - val_generative_discriminator_fake_outputs_loss: 0.6419 - val_x_logits_loss: 54390.6055 - val_x_logits_psnr: 7.8881 - val_x_logits_ssmi: 0.1371 - val_x_logits_sharp_diff: 11.9713\n",
      "\r"
     ]
    }
   ],
   "source": [
    "ae.fit(\n",
    "    x=train_ds,\n",
    "    input_kw=None,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=int(1e6), \n",
    "    verbose=2,\n",
    "    callbacks=[ es, ms, csv_log, sg],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_mean, is_sigma = inception_score(ae, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'inception_score mean: {is_mean}, sigma: {is_sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis_score = frechet_inception_distance(ae, training_generator, tolerance_threshold=1e-6, max_iteration=10, batch_size=32)\n",
    "print(f'frechet inception distance: {fis_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.perceptual_path_length import perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_mean_score = perceptual_path_length_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100, batch_size=32)\n",
    "print(f'perceptual path length score: {ppl_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_precision_score = precision_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'precision score: {_precision_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_recall_score = recall_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=100)\n",
    "print(f'recall score: {_recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import reconstruct_from_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_like_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'random_synthetic_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_randomly(ae, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import interpolate_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 19.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'interpolate_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "interpolate_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
