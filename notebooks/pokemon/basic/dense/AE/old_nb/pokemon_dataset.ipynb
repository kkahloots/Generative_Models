{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_KERAS=1\n",
      "\\\n"
     ]
    }
   ],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "\n",
    "import sys\n",
    "sys.path.append('..'+sep_local+'..')\n",
    "print(sep_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalid\\Documents\\projects\\Generative_Models\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..'+sep_local+'..'+sep_local+'..'+sep_local+'..'+sep_local+'..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='pokemon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'C:\\\\Users\\\\Khalid\\\\Documents\\projects\\\\pokemon\\DS06\\\\'\n",
    "validation_percentage = 0\n",
    "valid_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.file_image_generator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEBUG    | Looking for images in 'all'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | 809 file found\n"
     ]
    }
   ],
   "source": [
    "imgs_list = create_image_lists(\n",
    "    image_dir=images_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': {'dir': 'all',\n",
       "  'training': ['001.png',\n",
       "   '002.png',\n",
       "   '003.png',\n",
       "   '004.png',\n",
       "   '005.png',\n",
       "   '006.png',\n",
       "   '007.png',\n",
       "   '008.png',\n",
       "   '009.png',\n",
       "   '010.png',\n",
       "   '011.png',\n",
       "   '012.png',\n",
       "   '013.png',\n",
       "   '014.png',\n",
       "   '015.png',\n",
       "   '016.png',\n",
       "   '017.png',\n",
       "   '018.png',\n",
       "   '019.png',\n",
       "   '020.png',\n",
       "   '021.png',\n",
       "   '022.png',\n",
       "   '023.png',\n",
       "   '024.png',\n",
       "   '025.png',\n",
       "   '026.png',\n",
       "   '027.png',\n",
       "   '028.png',\n",
       "   '029.png',\n",
       "   '030.png',\n",
       "   '031.png',\n",
       "   '032.png',\n",
       "   '033.png',\n",
       "   '034.png',\n",
       "   '035.png',\n",
       "   '036.png',\n",
       "   '037.png',\n",
       "   '038.png',\n",
       "   '039.png',\n",
       "   '040.png',\n",
       "   '041.png',\n",
       "   '042.png',\n",
       "   '043.png',\n",
       "   '044.png',\n",
       "   '045.png',\n",
       "   '046.png',\n",
       "   '047.png',\n",
       "   '048.png',\n",
       "   '049.png',\n",
       "   '050.png',\n",
       "   '051.png',\n",
       "   '052.png',\n",
       "   '053.png',\n",
       "   '054.png',\n",
       "   '055.png',\n",
       "   '056.png',\n",
       "   '057.png',\n",
       "   '058.png',\n",
       "   '059.png',\n",
       "   '060.png',\n",
       "   '061.png',\n",
       "   '062.png',\n",
       "   '063.png',\n",
       "   '064.png',\n",
       "   '065.png',\n",
       "   '066.png',\n",
       "   '067.png',\n",
       "   '068.png',\n",
       "   '069.png',\n",
       "   '070.png',\n",
       "   '071.png',\n",
       "   '072.png',\n",
       "   '073.png',\n",
       "   '074.png',\n",
       "   '075.png',\n",
       "   '076.png',\n",
       "   '077.png',\n",
       "   '078.png',\n",
       "   '079.png',\n",
       "   '080.png',\n",
       "   '081.png',\n",
       "   '082.png',\n",
       "   '083.png',\n",
       "   '084.png',\n",
       "   '085.png',\n",
       "   '086.png',\n",
       "   '087.png',\n",
       "   '088.png',\n",
       "   '089.png',\n",
       "   '090.png',\n",
       "   '091.png',\n",
       "   '092.png',\n",
       "   '093.png',\n",
       "   '094.png',\n",
       "   '095.png',\n",
       "   '096.png',\n",
       "   '097.png',\n",
       "   '098.png',\n",
       "   '099.png',\n",
       "   '100.png',\n",
       "   '101.png',\n",
       "   '102.png',\n",
       "   '103.png',\n",
       "   '104.png',\n",
       "   '105.png',\n",
       "   '106.png',\n",
       "   '107.png',\n",
       "   '108.png',\n",
       "   '109.png',\n",
       "   '110.png',\n",
       "   '111.png',\n",
       "   '112.png',\n",
       "   '113.png',\n",
       "   '114.png',\n",
       "   '115.png',\n",
       "   '116.png',\n",
       "   '117.png',\n",
       "   '118.png',\n",
       "   '119.png',\n",
       "   '120.png',\n",
       "   '121.png',\n",
       "   '122.png',\n",
       "   '123.png',\n",
       "   '124.png',\n",
       "   '125.png',\n",
       "   '126.png',\n",
       "   '127.png',\n",
       "   '128.png',\n",
       "   '129.png',\n",
       "   '130.png',\n",
       "   '131.png',\n",
       "   '132.png',\n",
       "   '133.png',\n",
       "   '134.png',\n",
       "   '135.png',\n",
       "   '136.png',\n",
       "   '137.png',\n",
       "   '138.png',\n",
       "   '139.png',\n",
       "   '140.png',\n",
       "   '141.png',\n",
       "   '142.png',\n",
       "   '143.png',\n",
       "   '144.png',\n",
       "   '145.png',\n",
       "   '146.png',\n",
       "   '147.png',\n",
       "   '148.png',\n",
       "   '149.png',\n",
       "   '150.png',\n",
       "   '151.png',\n",
       "   '152.png',\n",
       "   '153.png',\n",
       "   '154.png',\n",
       "   '155.png',\n",
       "   '156.png',\n",
       "   '157.png',\n",
       "   '158.png',\n",
       "   '159.png',\n",
       "   '160.png',\n",
       "   '161.png',\n",
       "   '162.png',\n",
       "   '163.png',\n",
       "   '164.png',\n",
       "   '165.png',\n",
       "   '166.png',\n",
       "   '167.png',\n",
       "   '168.png',\n",
       "   '169.png',\n",
       "   '170.png',\n",
       "   '171.png',\n",
       "   '172.png',\n",
       "   '173.png',\n",
       "   '174.png',\n",
       "   '175.png',\n",
       "   '176.png',\n",
       "   '177.png',\n",
       "   '178.png',\n",
       "   '179.png',\n",
       "   '180.png',\n",
       "   '181.png',\n",
       "   '182.png',\n",
       "   '183.png',\n",
       "   '184.png',\n",
       "   '185.png',\n",
       "   '186.png',\n",
       "   '187.png',\n",
       "   '188.png',\n",
       "   '189.png',\n",
       "   '190.png',\n",
       "   '191.png',\n",
       "   '192.png',\n",
       "   '193.png',\n",
       "   '194.png',\n",
       "   '195.png',\n",
       "   '196.png',\n",
       "   '197.png',\n",
       "   '198.png',\n",
       "   '199.png',\n",
       "   '200.png',\n",
       "   '201.png',\n",
       "   '202.png',\n",
       "   '203.png',\n",
       "   '204.png',\n",
       "   '205.png',\n",
       "   '206.png',\n",
       "   '207.png',\n",
       "   '208.png',\n",
       "   '209.png',\n",
       "   '210.png',\n",
       "   '211.png',\n",
       "   '212.png',\n",
       "   '213.png',\n",
       "   '214.png',\n",
       "   '215.png',\n",
       "   '216.png',\n",
       "   '217.png',\n",
       "   '218.png',\n",
       "   '219.png',\n",
       "   '220.png',\n",
       "   '221.png',\n",
       "   '222.png',\n",
       "   '223.png',\n",
       "   '224.png',\n",
       "   '225.png',\n",
       "   '226.png',\n",
       "   '227.png',\n",
       "   '228.png',\n",
       "   '229.png',\n",
       "   '230.png',\n",
       "   '231.png',\n",
       "   '232.png',\n",
       "   '233.png',\n",
       "   '234.png',\n",
       "   '235.png',\n",
       "   '236.png',\n",
       "   '237.png',\n",
       "   '238.png',\n",
       "   '239.png',\n",
       "   '240.png',\n",
       "   '241.png',\n",
       "   '242.png',\n",
       "   '243.png',\n",
       "   '244.png',\n",
       "   '245.png',\n",
       "   '246.png',\n",
       "   '247.png',\n",
       "   '248.png',\n",
       "   '249.png',\n",
       "   '250.png',\n",
       "   '251.png',\n",
       "   '252.png',\n",
       "   '253.png',\n",
       "   '254.png',\n",
       "   '255.png',\n",
       "   '256.png',\n",
       "   '257.png',\n",
       "   '258.png',\n",
       "   '259.png',\n",
       "   '260.png',\n",
       "   '261.png',\n",
       "   '262.png',\n",
       "   '263.png',\n",
       "   '264.png',\n",
       "   '265.png',\n",
       "   '266.png',\n",
       "   '267.png',\n",
       "   '268.png',\n",
       "   '269.png',\n",
       "   '270.png',\n",
       "   '271.png',\n",
       "   '272.png',\n",
       "   '273.png',\n",
       "   '274.png',\n",
       "   '275.png',\n",
       "   '276.png',\n",
       "   '277.png',\n",
       "   '278.png',\n",
       "   '279.png',\n",
       "   '280.png',\n",
       "   '281.png',\n",
       "   '282.png',\n",
       "   '283.png',\n",
       "   '284.png',\n",
       "   '285.png',\n",
       "   '286.png',\n",
       "   '287.png',\n",
       "   '288.png',\n",
       "   '289.png',\n",
       "   '290.png',\n",
       "   '291.png',\n",
       "   '292.png',\n",
       "   '293.png',\n",
       "   '294.png',\n",
       "   '295.png',\n",
       "   '296.png',\n",
       "   '297.png',\n",
       "   '298.png',\n",
       "   '299.png',\n",
       "   '300.png',\n",
       "   '301.png',\n",
       "   '302.png',\n",
       "   '303.png',\n",
       "   '304.png',\n",
       "   '305.png',\n",
       "   '306.png',\n",
       "   '307.png',\n",
       "   '308.png',\n",
       "   '309.png',\n",
       "   '310.png',\n",
       "   '311.png',\n",
       "   '312.png',\n",
       "   '313.png',\n",
       "   '314.png',\n",
       "   '315.png',\n",
       "   '316.png',\n",
       "   '317.png',\n",
       "   '318.png',\n",
       "   '319.png',\n",
       "   '320.png',\n",
       "   '321.png',\n",
       "   '322.png',\n",
       "   '323.png',\n",
       "   '324.png',\n",
       "   '325.png',\n",
       "   '326.png',\n",
       "   '327.png',\n",
       "   '328.png',\n",
       "   '329.png',\n",
       "   '330.png',\n",
       "   '331.png',\n",
       "   '332.png',\n",
       "   '333.png',\n",
       "   '334.png',\n",
       "   '335.png',\n",
       "   '336.png',\n",
       "   '337.png',\n",
       "   '338.png',\n",
       "   '339.png',\n",
       "   '340.png',\n",
       "   '341.png',\n",
       "   '342.png',\n",
       "   '343.png',\n",
       "   '344.png',\n",
       "   '345.png',\n",
       "   '346.png',\n",
       "   '347.png',\n",
       "   '348.png',\n",
       "   '349.png',\n",
       "   '350.png',\n",
       "   '351.png',\n",
       "   '352.png',\n",
       "   '353.png',\n",
       "   '354.png',\n",
       "   '355.png',\n",
       "   '356.png',\n",
       "   '357.png',\n",
       "   '358.png',\n",
       "   '359.png',\n",
       "   '360.png',\n",
       "   '361.png',\n",
       "   '362.png',\n",
       "   '363.png',\n",
       "   '364.png',\n",
       "   '365.png',\n",
       "   '366.png',\n",
       "   '367.png',\n",
       "   '368.png',\n",
       "   '369.png',\n",
       "   '370.png',\n",
       "   '371.png',\n",
       "   '372.png',\n",
       "   '373.png',\n",
       "   '374.png',\n",
       "   '375.png',\n",
       "   '376.png',\n",
       "   '377.png',\n",
       "   '378.png',\n",
       "   '379.png',\n",
       "   '380.png',\n",
       "   '381.png',\n",
       "   '382.png',\n",
       "   '383.png',\n",
       "   '384.png',\n",
       "   '385.png',\n",
       "   '386.png',\n",
       "   '387.png',\n",
       "   '388.png',\n",
       "   '389.png',\n",
       "   '390.png',\n",
       "   '391.png',\n",
       "   '392.png',\n",
       "   '393.png',\n",
       "   '394.png',\n",
       "   '395.png',\n",
       "   '396.png',\n",
       "   '397.png',\n",
       "   '398.png',\n",
       "   '399.png',\n",
       "   '400.png',\n",
       "   '401.png',\n",
       "   '402.png',\n",
       "   '403.png',\n",
       "   '404.png',\n",
       "   '405.png',\n",
       "   '406.png',\n",
       "   '407.png',\n",
       "   '408.png',\n",
       "   '409.png',\n",
       "   '410.png',\n",
       "   '411.png',\n",
       "   '412.png',\n",
       "   '413.png',\n",
       "   '414.png',\n",
       "   '415.png',\n",
       "   '416.png',\n",
       "   '417.png',\n",
       "   '418.png',\n",
       "   '419.png',\n",
       "   '420.png',\n",
       "   '421.png',\n",
       "   '422.png',\n",
       "   '423.png',\n",
       "   '424.png',\n",
       "   '425.png',\n",
       "   '426.png',\n",
       "   '427.png',\n",
       "   '428.png',\n",
       "   '429.png',\n",
       "   '430.png',\n",
       "   '431.png',\n",
       "   '432.png',\n",
       "   '433.png',\n",
       "   '434.png',\n",
       "   '435.png',\n",
       "   '436.png',\n",
       "   '437.png',\n",
       "   '438.png',\n",
       "   '439.png',\n",
       "   '440.png',\n",
       "   '441.png',\n",
       "   '442.png',\n",
       "   '443.png',\n",
       "   '444.png',\n",
       "   '445.png',\n",
       "   '446.png',\n",
       "   '447.png',\n",
       "   '448.png',\n",
       "   '449.png',\n",
       "   '450.png',\n",
       "   '451.png',\n",
       "   '452.png',\n",
       "   '453.png',\n",
       "   '454.png',\n",
       "   '455.png',\n",
       "   '456.png',\n",
       "   '457.png',\n",
       "   '458.png',\n",
       "   '459.png',\n",
       "   '460.png',\n",
       "   '461.png',\n",
       "   '462.png',\n",
       "   '463.png',\n",
       "   '464.png',\n",
       "   '465.png',\n",
       "   '466.png',\n",
       "   '467.png',\n",
       "   '468.png',\n",
       "   '469.png',\n",
       "   '470.png',\n",
       "   '471.png',\n",
       "   '472.png',\n",
       "   '473.png',\n",
       "   '474.png',\n",
       "   '475.png',\n",
       "   '476.png',\n",
       "   '477.png',\n",
       "   '478.png',\n",
       "   '479.png',\n",
       "   '480.png',\n",
       "   '481.png',\n",
       "   '482.png',\n",
       "   '483.png',\n",
       "   '484.png',\n",
       "   '485.png',\n",
       "   '486.png',\n",
       "   '487.png',\n",
       "   '488.png',\n",
       "   '489.png',\n",
       "   '490.png',\n",
       "   '491.png',\n",
       "   '492.png',\n",
       "   '493.png',\n",
       "   '494.png',\n",
       "   '495.png',\n",
       "   '496.png',\n",
       "   '497.png',\n",
       "   '498.png',\n",
       "   '499.png',\n",
       "   '500.png',\n",
       "   '501.png',\n",
       "   '502.png',\n",
       "   '503.png',\n",
       "   '504.png',\n",
       "   '505.png',\n",
       "   '506.png',\n",
       "   '507.png',\n",
       "   '508.png',\n",
       "   '509.png',\n",
       "   '510.png',\n",
       "   '511.png',\n",
       "   '512.png',\n",
       "   '513.png',\n",
       "   '514.png',\n",
       "   '515.png',\n",
       "   '516.png',\n",
       "   '517.png',\n",
       "   '518.png',\n",
       "   '519.png',\n",
       "   '520.png',\n",
       "   '521.png',\n",
       "   '522.png',\n",
       "   '523.png',\n",
       "   '524.png',\n",
       "   '525.png',\n",
       "   '526.png',\n",
       "   '527.png',\n",
       "   '528.png',\n",
       "   '529.png',\n",
       "   '530.png',\n",
       "   '531.png',\n",
       "   '532.png',\n",
       "   '533.png',\n",
       "   '534.png',\n",
       "   '535.png',\n",
       "   '536.png',\n",
       "   '537.png',\n",
       "   '538.png',\n",
       "   '539.png',\n",
       "   '540.png',\n",
       "   '541.png',\n",
       "   '542.png',\n",
       "   '543.png',\n",
       "   '544.png',\n",
       "   '545.png',\n",
       "   '546.png',\n",
       "   '547.png',\n",
       "   '548.png',\n",
       "   '549.png',\n",
       "   '550.png',\n",
       "   '551.png',\n",
       "   '552.png',\n",
       "   '553.png',\n",
       "   '554.png',\n",
       "   '555.png',\n",
       "   '556.png',\n",
       "   '557.png',\n",
       "   '558.png',\n",
       "   '559.png',\n",
       "   '560.png',\n",
       "   '561.png',\n",
       "   '562.png',\n",
       "   '563.png',\n",
       "   '564.png',\n",
       "   '565.png',\n",
       "   '566.png',\n",
       "   '567.png',\n",
       "   '568.png',\n",
       "   '569.png',\n",
       "   '570.png',\n",
       "   '571.png',\n",
       "   '572.png',\n",
       "   '573.png',\n",
       "   '574.png',\n",
       "   '575.png',\n",
       "   '576.png',\n",
       "   '577.png',\n",
       "   '578.png',\n",
       "   '579.png',\n",
       "   '580.png',\n",
       "   '581.png',\n",
       "   '582.png',\n",
       "   '583.png',\n",
       "   '584.png',\n",
       "   '585.png',\n",
       "   '586.png',\n",
       "   '587.png',\n",
       "   '588.png',\n",
       "   '589.png',\n",
       "   '590.png',\n",
       "   '591.png',\n",
       "   '592.png',\n",
       "   '593.png',\n",
       "   '594.png',\n",
       "   '595.png',\n",
       "   '596.png',\n",
       "   '597.png',\n",
       "   '598.png',\n",
       "   '599.png',\n",
       "   '600.png',\n",
       "   '601.png',\n",
       "   '602.png',\n",
       "   '603.png',\n",
       "   '604.png',\n",
       "   '605.png',\n",
       "   '606.png',\n",
       "   '607.png',\n",
       "   '608.png',\n",
       "   '609.png',\n",
       "   '610.png',\n",
       "   '611.png',\n",
       "   '612.png',\n",
       "   '613.png',\n",
       "   '614.png',\n",
       "   '615.png',\n",
       "   '616.png',\n",
       "   '617.png',\n",
       "   '618.png',\n",
       "   '619.png',\n",
       "   '620.png',\n",
       "   '621.png',\n",
       "   '622.png',\n",
       "   '623.png',\n",
       "   '624.png',\n",
       "   '625.png',\n",
       "   '626.png',\n",
       "   '627.png',\n",
       "   '628.png',\n",
       "   '629.png',\n",
       "   '630.png',\n",
       "   '631.png',\n",
       "   '632.png',\n",
       "   '633.png',\n",
       "   '634.png',\n",
       "   '635.png',\n",
       "   '636.png',\n",
       "   '637.png',\n",
       "   '638.png',\n",
       "   '639.png',\n",
       "   '640.png',\n",
       "   '641.png',\n",
       "   '642.png',\n",
       "   '643.png',\n",
       "   '644.png',\n",
       "   '645.png',\n",
       "   '646.png',\n",
       "   '647.png',\n",
       "   '648.png',\n",
       "   '649.png',\n",
       "   '650.png',\n",
       "   '651.png',\n",
       "   '652.png',\n",
       "   '653.png',\n",
       "   '654.png',\n",
       "   '655.png',\n",
       "   '656.png',\n",
       "   '657.png',\n",
       "   '658.png',\n",
       "   '659.png',\n",
       "   '660.png',\n",
       "   '661.png',\n",
       "   '662r.png',\n",
       "   '663.png',\n",
       "   '664.png',\n",
       "   '665.png',\n",
       "   '666.png',\n",
       "   '667.png',\n",
       "   '668.png',\n",
       "   '669.png',\n",
       "   '670.png',\n",
       "   '671.png',\n",
       "   '672.png',\n",
       "   '673.png',\n",
       "   '674.png',\n",
       "   '675.png',\n",
       "   '676.png',\n",
       "   '677.png',\n",
       "   '678.png',\n",
       "   '679.png',\n",
       "   '680.png',\n",
       "   '681.png',\n",
       "   '682.png',\n",
       "   '683.png',\n",
       "   '684.png',\n",
       "   '685.png',\n",
       "   '686.png',\n",
       "   '687.png',\n",
       "   '688.png',\n",
       "   '689.png',\n",
       "   '690.png',\n",
       "   '691.png',\n",
       "   '692.png',\n",
       "   '693.png',\n",
       "   '694.png',\n",
       "   '695.png',\n",
       "   '696.png',\n",
       "   '697.png',\n",
       "   '698.png',\n",
       "   '699.png',\n",
       "   '700.png',\n",
       "   '701.png',\n",
       "   '702.png',\n",
       "   '703.png',\n",
       "   '704.png',\n",
       "   '705.png',\n",
       "   '706.png',\n",
       "   '707.png',\n",
       "   '708.png',\n",
       "   '709.png',\n",
       "   '710.png',\n",
       "   '711.png',\n",
       "   '712.png',\n",
       "   '713.png',\n",
       "   '714.png',\n",
       "   '715.png',\n",
       "   '716.png',\n",
       "   '717.png',\n",
       "   '718.png',\n",
       "   '719.png',\n",
       "   '720.png',\n",
       "   '721.png',\n",
       "   '722.png',\n",
       "   '723.png',\n",
       "   '724.png',\n",
       "   '725.png',\n",
       "   '726.png',\n",
       "   '727.png',\n",
       "   '728.png',\n",
       "   '729.png',\n",
       "   '730.png',\n",
       "   '731.png',\n",
       "   '732.png',\n",
       "   '733.png',\n",
       "   '734.png',\n",
       "   '735.png',\n",
       "   '736.png',\n",
       "   '737.png',\n",
       "   '738.png',\n",
       "   '739.png',\n",
       "   '740le.png',\n",
       "   '741.png',\n",
       "   '742.png',\n",
       "   '743.png',\n",
       "   '744.png',\n",
       "   '745.png',\n",
       "   '746.png',\n",
       "   '747.png',\n",
       "   '748.png',\n",
       "   '749.png',\n",
       "   '750.png',\n",
       "   '751.png',\n",
       "   '752.png',\n",
       "   '753.png',\n",
       "   '754.png',\n",
       "   '755.png',\n",
       "   '756.png',\n",
       "   '757.png',\n",
       "   '758.png',\n",
       "   '759.png',\n",
       "   '760.png',\n",
       "   '761.png',\n",
       "   '762.png',\n",
       "   '763.png',\n",
       "   '764.png',\n",
       "   '765.png',\n",
       "   '766.png',\n",
       "   '767.png',\n",
       "   '768.png',\n",
       "   '769.png',\n",
       "   '770.png',\n",
       "   '771.png',\n",
       "   '772.png',\n",
       "   '773.png',\n",
       "   '774.png',\n",
       "   '775.png',\n",
       "   '776.png',\n",
       "   '777.png',\n",
       "   '778.png',\n",
       "   '779.png',\n",
       "   '780.png',\n",
       "   '781.png',\n",
       "   '782.png',\n",
       "   '783.png',\n",
       "   '784.png',\n",
       "   '785.png',\n",
       "   '786.png',\n",
       "   '787.png',\n",
       "   '788.png',\n",
       "   '789.png',\n",
       "   '790.png',\n",
       "   '791.png',\n",
       "   '792.png',\n",
       "   '793.png',\n",
       "   '794.png',\n",
       "   '795.png',\n",
       "   '796.png',\n",
       "   '797.png',\n",
       "   '798.png',\n",
       "   '799.png',\n",
       "   '800.png',\n",
       "   '801.png',\n",
       "   '802.png',\n",
       "   '803.png',\n",
       "   '804.png',\n",
       "   '805.png',\n",
       "   '806.png',\n",
       "   '807.png',\n",
       "   '808.png',\n",
       "   '809.png'],\n",
       "  'validation': []}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmdb\n",
    "from keras.preprocessing.image import Iterator, load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lmdb(filename, imgs_dict):\n",
    "    lmdb_env = lmdb.open(filename)\n",
    "    lmdb_db = lmdb_env.begin(write=True)\n",
    "    for k, v in imgs_dict:\n",
    "        lmdb_db.put(k, v)\n",
    "    \n",
    "\n",
    "img_to_array(\n",
    "    load_img(\n",
    "        sorted_filenames[ix],\n",
    "        grayscale=grayscale,\n",
    "        target_size=self.target_size\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import get_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_lmdb(\n",
    "             image_lists,\n",
    "             category, \n",
    "             image_dir,\n",
    "             target_size=(256, 256, 3),\n",
    "             color_mode='rgb',\n",
    "             class_mode='categorical',\n",
    "             batch_size=32,\n",
    "             episode_len=20,\n",
    "             episode_shift=10,\n",
    "             shuffle=True,\n",
    "             seed=None,\n",
    "             data_format=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='jpeg',\n",
    "             dtype=K.floatx()\n",
    "             ):\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "\n",
    "    classes = list(image_lists.keys())\n",
    "\n",
    "    num_class = len(classes)\n",
    "\n",
    "    how_many_files = 0\n",
    "    for label_name in classes:\n",
    "        for _ in image_lists[label_name][category]:\n",
    "            how_many_files += 1\n",
    "\n",
    "    samples = how_many_files\n",
    "    class2id = dict(zip(classes, range(len(classes))))\n",
    "    id2class = dict((v, k) for k, v in class2id.items())\n",
    "    classes = np.zeros((samples,), dtype='int32')\n",
    "\n",
    "    #self.image_data_generator = image_data_generator\n",
    "    target_size = tuple(target_size)\n",
    "    if color_mode not in {'rgb', 'grayscale'}:\n",
    "        raise ValueError('Invalid color mode:', color_mode,\n",
    "                         '; expected \"rgb\" or \"grayscale\".')\n",
    "\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for label_name in classes:\n",
    "        for j, _ in enumerate(image_lists[label_name][category]):\n",
    "            classes[i] = class2id[label_name]\n",
    "            img_path = get_file_path(image_lists,\n",
    "                                      label_name,\n",
    "                                      j,\n",
    "                                      image_dir,\n",
    "                                      category)\n",
    "            img = img_to_array(\n",
    "                            load_img(\n",
    "                            img_path,\n",
    "                            grayscale=color_mode=='grayscale',\n",
    "                            target_size=target_size\n",
    "                            )\n",
    "                        )\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras_preprocessing.image.utils.load_img(path, grayscale=False, color_mode='rgb', target_size=None, interpolation='nearest')>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape= image_size=(100, 100, 3)\n",
    "batch_size = 32\n",
    "latents_dim = 32\n",
    "intermediate_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 662 training files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  INFO     | Found 147 validation files\n"
     ]
    }
   ],
   "source": [
    "training_generator, testing_generator = get_generators(\n",
    "    images_list=imgs_list, \n",
    "    image_dir=images_dir, \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size, \n",
    "    class_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: training_generator, \n",
    "    output_types=tf.float32 ,\n",
    "    output_shapes=tf.TensorShape((batch_size, ) + image_size)\n",
    ")\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: testing_generator, \n",
    "    output_types=tf.float32 ,\n",
    "    output_shapes=tf.TensorShape((batch_size, ) + image_size)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data[0].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_instance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(inputs_shape, Iterable):\n",
    "    _outputs_shape = np.prod(inputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_outputs_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lays = [tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=latents_dim)]\n",
    "\n",
    "dec_lays = [tf.keras.layers.Dense(units=latents_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=intermediate_dim, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=_outputs_shape),\n",
    "            tf.keras.layers.Reshape(inputs_shape)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'AE_Dense_reconst_ell'\n",
    "experiments_dir='experiments'+sep_local+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.autoencoding_basic.autoencoders.autoencoder import autoencoder as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_shape=image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latents_dim,\n",
    "        'layers': enc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latents_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(experiments_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonAE_Dense_reconst_ell\\\\var_save_dir'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_if_not_exist(_restore)\n",
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to restore trained model, set filepath=_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEBUG    | Restore old models ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inference\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100, 100, 50)      200       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 100, 50)      2550      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 500000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                16000032  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activity_regularization (Act (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "inference_outputs (Activatio (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 16,002,910\n",
      "Trainable params: 16,002,846\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generative\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generative_inputs (InputLaye [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                1650      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30000)             1530000   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 100, 3)       12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "activity_regularization_1 (A (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "generative_outputs (Activati (None, 100, 100, 3)       0         \n",
      "=================================================================\n",
      "Total params: 1,532,718\n",
      "Trainable params: 1,532,712\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING  | None\n"
     ]
    }
   ],
   "source": [
    "ae = AE( \n",
    "    name=model_name,\n",
    "    latents_dim=latents_dim,\n",
    "    batch_size=batch_size,\n",
    "    variables_params=variables_params, \n",
    "    filepath=_restore\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pokemonAE_Dense_reconst_ell\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_inputs (InputLayer [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inference (Model)            (None, 32)                16002910  \n",
      "_________________________________________________________________\n",
      "generative (Model)           (None, 100, 100, 3)       1532718   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_x_logits (Tensor [(None, 100, 100, 3)]     0         \n",
      "=================================================================\n",
      "Total params: 17,535,628\n",
      "Trainable params: 17,535,558\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#ae.compile(metrics=None)\n",
    "ae.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=6, \n",
    "    verbose=1, \n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\pokemonAE_Dense_reconst_ell\\\\csv_dir\\\\pokemonAE_Dense_reconst_ell.csv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dir = os.path.join(experiments_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, ae.name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(experiments_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latents_shape=latents_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ae.fit(\n",
    "#    x=train_ds,\n",
    "#    input_kw=None,\n",
    "#    steps_per_epoch=int(1e4),\n",
    "#    epochs=int(1e6), \n",
    "#    verbose=2,\n",
    "#    callbacks=[ es, ms, csv_log, sg],\n",
    "#    workers=-1,\n",
    "#    use_multiprocessing=True,\n",
    "#    validation_data=test_ds,\n",
    "#    validation_steps=int(1e4)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the inception_score mean ...\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 75, 3) for input Tensor(\"input_1:0\", shape=(None, 75, 75, 3), dtype=float32), but it was called on an input with incompatible shape (32, 100, 100, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [1:42:45, 30.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the inception_score sigma ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:780: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "0it [00:00, ?it/s]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\core.py:119: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return func(*args2)\n",
      "200it [1:42:40, 30.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_score mean: dask.array<mean_agg-aggregate, shape=(1,), dtype=float64, chunksize=(1,), chunktype=numpy.ndarray>, sigma: dask.array<getitem, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "is_mean, is_sigma = inception_score(ae, tolerance_threshold=1e-6, max_iteration=200)\n",
    "print(f'inception_score mean: {is_mean}, sigma: {is_sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.inception_metrics import frechet_inception_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the inception images sigma ...\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 75, 75, 3) for input Tensor(\"input_2:0\", shape=(None, 75, 75, 3), dtype=float32), but it was called on an input with incompatible shape (32, 100, 100, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "1it [05:04, 304.38s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "2it [14:37, 384.91s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "3it [29:01, 528.86s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "4it [46:43, 688.70s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "5it [1:07:41, 859.56s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "6it [1:29:21, 991.59s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "7it [1:56:20, 1179.76s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "8it [2:26:19, 1365.57s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "9it [2:55:37, 1483.34s/it]C:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\dask\\array\\routines.py:271: PerformanceWarning: Increasing number of chunks by factor of 656\n",
      "  axes=(left_axes, right_axes),\n",
      "10it [3:27:52, 1618.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the inception images mean ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the generated images sigma ...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'inference_inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-f7960b05bb3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfis_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrechet_inception_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'frechet inception distance: {fis_score}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\evaluation\\generativity_metrics\\inception_metrics.py\u001b[0m in \u001b[0;36mfrechet_inception_distance\u001b[1;34m(model, data_generator, tolerance_threshold, max_iteration, batch_size)\u001b[0m\n\u001b[0;32m    179\u001b[0m     generated_images_sigma = bootstrapping_additive(\n\u001b[0;32m    180\u001b[0m         \u001b[0mdata_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerated_predictions_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mstopping_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\evaluation\\generativity_metrics\\shared_api.py\u001b[0m in \u001b[0;36mbootstrapping_additive\u001b[1;34m(data_generator, func, stopping_func, tolerance_threshold, max_iteration)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbootstrapping_additive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopping_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopping_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\evaluation\\generativity_metrics\\inception_metrics.py\u001b[0m in \u001b[0;36mgenerated_predictions_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrayscale_to_rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mlatents_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;31m# Generate random latents and interpolation t-values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\training\\autoencoding_basic\\autoencoders\\autoencoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# autoencoder function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__encode__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'inputs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'z_latents'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;31m# autoencoder function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\training\\autoencoding_basic\\autoencoders\\autoencoder.py\u001b[0m in \u001b[0;36m__encode__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'latents_shape'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatents_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# autoencoder function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\graphs\\basics\\AE_graph.py\u001b[0m in \u001b[0;36mencode_fn\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inputs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inference'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     return {\n\u001b[0;32m     51\u001b[0m         \u001b[1;34m'z_latents'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\Generative_Models\\training\\autoencoding_basic\\autoencoders\\autoencoder.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_name, param)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init_autoencoder__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;31m# can ignore it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flatten_to_reference_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m       \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_flatten_to_reference_inputs\u001b[1;34m(self, tensors)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# Flatten in the order the `Input`s were passed during Model construction.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mref_inputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;31m# Otherwise both self.inputs and tensors will already be in same order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf02\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# Flatten in the order the `Input`s were passed during Model construction.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mref_inputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;31m# Otherwise both self.inputs and tensors will already be in same order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'inference_inputs'"
     ]
    }
   ],
   "source": [
    "fis_score = frechet_inception_distance(ae, training_generator, tolerance_threshold=1e-6, max_iteration=10, batch_size=32)\n",
    "print(f'frechet inception distance: {fis_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.perceptual_path_length import perceptual_path_length_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_mean_score = perceptual_path_length_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=200, batch_size=32)\n",
    "print(f'perceptual path length score: {ppl_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_precision_score = precision_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=200)\n",
    "print(f'precision score: {_precision_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generativity_metrics.precision_recall import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_recall_score = recall_score(ae, training_generator, tolerance_threshold=1e-6, max_iteration=200)\n",
    "print(f'recall score: {_recall_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import reconstruct_from_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'reconstruct_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "reconstruct_from_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_like_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_training_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, training_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'generate_testing_images_like_a_batch_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_like_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import generate_images_randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'random_synthetic_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "generate_images_randomly(ae, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.image_generation_testing import interpolate_a_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "save_dir = os.path.join(experiments_dir, 'interpolate_dir')\n",
    "create_if_not_exist(save_dir)\n",
    "\n",
    "interpolate_a_batch(ae, testing_generator, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
