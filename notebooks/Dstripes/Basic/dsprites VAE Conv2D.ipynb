{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "sep_local = os.path.sep\n",
    "sep_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TF_KERAS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='dsprites',\n",
      "    version=0.1.0,\n",
      "    description='dSprites is a dataset of 2D shapes procedurally generated from 6 ground truth\n",
      "independent latent factors. These factors are *color*, *shape*, *scale*,\n",
      "*rotation*, *x* and *y* positions of a sprite.\n",
      "\n",
      "All possible combinations of these latents are present exactly once,\n",
      "generating N = 737280 total images.\n",
      "\n",
      "### Latent factor values\n",
      "\n",
      "*   Color: white\n",
      "*   Shape: square, ellipse, heart\n",
      "*   Scale: 6 values linearly spaced in [0.5, 1]\n",
      "*   Orientation: 40 values in [0, 2 pi]\n",
      "*   Position X: 32 values in [0, 1]\n",
      "*   Position Y: 32 values in [0, 1]\n",
      "\n",
      "We varied one latent at a time (starting from Position Y, then Position X, etc),\n",
      "and sequentially stored the images in fixed order.\n",
      "Hence the order along the first dimension is fixed and allows you to map back to\n",
      "the value of the latents corresponding to that image.\n",
      "\n",
      "We chose the latents values deliberately to have the smallest step changes\n",
      "while ensuring that all pixel outputs were different. No noise was added.\n",
      "',\n",
      "    urls=['https://github.com/deepmind/dsprites-dataset'],\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(64, 64, 1), dtype=tf.uint8),\n",
      "        'label_orientation': ClassLabel(shape=(), dtype=tf.int64, num_classes=40),\n",
      "        'label_scale': ClassLabel(shape=(), dtype=tf.int64, num_classes=6),\n",
      "        'label_shape': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "        'label_x_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'label_y_position': ClassLabel(shape=(), dtype=tf.int64, num_classes=32),\n",
      "        'value_orientation': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_scale': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_shape': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_x_position': Tensor(shape=[], dtype=tf.float32),\n",
      "        'value_y_position': Tensor(shape=[], dtype=tf.float32),\n",
      "    }),\n",
      "    total_num_examples=737280,\n",
      "    splits={\n",
      "        'train': 737280,\n",
      "    },\n",
      "    supervised_keys=None,\n",
      "    citation=\"\"\"@misc{dsprites17,\n",
      "    author = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},\n",
      "    title = {dSprites: Disentanglement testing Sprites dataset},\n",
      "    howpublished= {https://github.com/deepmind/dsprites-dataset/},\n",
      "    year = \"2017\",\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..' + sep_local + '..' + sep_local + '..') # For Windows import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..' + sep_local + '..' + sep_local + '..') # For Linux import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.keras.backend.set_floatx('float32')\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_name = 'dsprites'\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "info = tfds.builder(dataset_name).info\n",
    "\n",
    "print(info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dim = 20\n",
    "inputs_shape=(64, 64, 1) # image shape\n",
    "batch_size = 100\n",
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = 600\n",
    "TEST_BUF = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# Construct a tf.data.Dataset\n",
    "train_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TRAIN_BUF).batch(batch_size)\n",
    "try:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TEST).shuffle(TEST_BUF).batch(batch_size)\n",
    "except:\n",
    "    test_ds = tfds.load(name=dataset_name, split=tfds.Split.TRAIN).shuffle(TEST_BUF).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data['image'][0].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enc_lays1 = [\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latent_dim)\n",
    "]\n",
    "\n",
    "enc_lays2 = [\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latent_dim)\n",
    "]\n",
    "\n",
    "dec_lays = [\n",
    "    tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    \n",
    "    # No activation\n",
    "    tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.data_and_files.file_utils import make_random_string\n",
    "#from time import gmtime, strftime\n",
    "\n",
    "#model_name = 'AE_' + make_random_string(5) + strftime(\"%a_%d_%b_%Y_%H_%M\", gmtime())\n",
    "#print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_name = dataset_name + 'Dense' +'AE'\n",
    "#recoding_dir='..'+sep_local+'..'+sep_local+'..'+sep_local+'recording'+sep_local + model_name\n",
    "os.getcwd()\n",
    "recoding_dir=os.getcwd()+ sep_local  +'recording'+sep_local + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "absolute = abspath(recoding_dir)\n",
    "print(\"Recording_dir\",absolute)\n",
    "print(\"Current working dir\",os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ef2a77ca3d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoencoders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAE\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'training'"
     ]
    }
   ],
   "source": [
    "from training.traditional.autoencoders.VAE import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'encoder_mean', \n",
    "        'inputs_shape': inputs_shape,\n",
    "        'outputs_shape': latent_dim,\n",
    "        'layers': enc_lays1\n",
    "    }\n",
    "    ,\n",
    "    \n",
    "     {\n",
    "        'name': 'encoder_logvar', \n",
    "        'inputs_shape': inputs_shape,\n",
    "        'outputs_shape': latent_dim,\n",
    "        'layers': enc_lays2\n",
    "    }\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape': latent_dim,\n",
    "        'outputs_shape': inputs_shape,\n",
    "        'layers': dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "_restore = os.path.join(recoding_dir, 'var_save_dir')\n",
    "create_if_not_exist(_restore)\n",
    "absolute = abspath(_restore)\n",
    "print(\"Restore_dir\",absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = VAE( \n",
    "    name=model_name,\n",
    "    inputs_shape=inputs_shape,\n",
    "    outputs_shape=inputs_shape,\n",
    "    latent_dim=latent_dim,\n",
    "    batch_size=batch_size,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None #to restore trained model, set filepath=_restore\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae.compile(metrics=None)\n",
    "ae.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)\n",
    "from training.callbacks.progress_bar import NotebookPrograssBar\n",
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e28298cc2eb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m vae.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minstance_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vae' is not defined"
     ]
    }
   ],
   "source": [
    "progbar = NotebookPrograssBar(leave_outer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore,save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.join(recoding_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, model_name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "absolute = abspath(csv_dir)\n",
    "print(\"Csv_dir\",absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(recoding_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)\n",
    "absolute = abspath(image_gen_dir)\n",
    "print(\"Image_gen_dir\",absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latent_shape=6, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DOWN_PATH = '..'+sep_local+'..'+sep_local+'..'+sep_local+'data'\n",
    "DATA_DOWN_PATH = os.getcwd() + sep_local+'data'\n",
    "Script_dir = os.getcwd() + sep_local+'data'+sep_local+'download_gt_data.sh'\n",
    "# Script call to download \"dsprites_full\" dataset_name \n",
    "!/bin/bash $Script_dir -f $DATA_DOWN_PATH -d $dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.gt_load.datasets import load\n",
    "DATA_PATH = DATA_DOWN_PATH +sep_local+'.gt_datasets'\n",
    "absolute = abspath(DATA_PATH)\n",
    "print(\"DATA_PATH\",absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = load(dataset_name='dsprites_full', dataset_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_csv = os.path.join(recoding_dir, 'csv_dir', 'gts_metrics')\n",
    "gtu_csv = os.path.join(recoding_dir, 'csv_dir', 'gtu_metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.callbacks.disentangle_supervied import DisentanglementSuperviedMetrics\n",
    "from training.callbacks.disentangle_unsupervied import DisentanglementUnsuperviedMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_mertics = DisentanglementSuperviedMetrics(            \n",
    "    ground_truth_data=eval_dataset,\n",
    "    representation_fn=lambda x: ae.encode(inputs={'x_mean': x, 'x_logvar': x})['x_latent'],\n",
    "    random_state=np.random.RandomState(0),\n",
    "    file_Name=gts_csv,\n",
    "    num_train=1000,\n",
    "    num_test=200,\n",
    "    batch_size=batch_size,\n",
    "    continuous_factors=False,\n",
    "    gt_freq=2\n",
    ")\n",
    "gtu_mertics = DisentanglementUnsuperviedMetrics(            \n",
    "    ground_truth_data=eval_dataset,\n",
    "    representation_fn=lambda x: ae.encode(inputs={'x_mean': x, 'x_logvar': x})['x_latent'],\n",
    "    random_state=np.random.RandomState(0),\n",
    "    file_Name=gtu_csv,\n",
    "    num_train=1000,\n",
    "    num_test=200,\n",
    "    batch_size=batch_size,\n",
    "    gt_freq=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ae.fit_generator(\n",
    "    generator=train_ds,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=100, \n",
    "    verbose=0,\n",
    "    callbacks=[progbar, es, ms, csv_log, sg, gts_mertics, gtu_mertics],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}