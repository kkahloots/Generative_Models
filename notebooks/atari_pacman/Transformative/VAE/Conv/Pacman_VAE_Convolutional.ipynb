{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TF_KERAS = 1\n",
    "import os\n",
    "sep_local = os.path.sep\n",
    "import sys\n",
    "sys.path.append('..' + sep_local + '..' + sep_local +'..' + sep_local + '..' + sep_local + '..') # For Windows import\n",
    "os.chdir('..' + sep_local + '..' + sep_local +'..' + sep_local + '..' + sep_local + '..') # For Linux import\n",
    "print(sep_local)\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='atari_pacman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = '/home/azeghost/datasets/.mspacman/atari_v1/screens/mspacman' #Linux\n",
    "#IMG_DIR = 'C:\\\\projects\\\\pokemon\\DS06\\\\'\n",
    "VAL_PCT = 25\n",
    "VAL_FORMAT = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.generators.file_image_generator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_list = create_image_lists(\n",
    "    image_dir=IMG_DIR, \n",
    "    validation_pct=VAL_PCT, \n",
    "    valid_imgae_formats=VAL_FORMAT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale=1\n",
    "# IMG_SIZE=(160//scale, 210//scale, 3)\n",
    "# BATCH_SIZE = 5\n",
    "# EPIS_LEN = 10\n",
    "# EPIS_SHIFT = 5\n",
    "\n",
    "\n",
    "# inputs_shape= IMG_SIZE\n",
    "# latent_dim = 10\n",
    "# intermediate_dim = 10\n",
    "\n",
    "scale=1\n",
    "IMG_SIZE=(160//scale, 210//scale, 3)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPIS_LEN = 10\n",
    "EPIS_SHIFT = 5\n",
    "\n",
    "inputs_shape= IMG_SIZE\n",
    "latent_dim = 30\n",
    "intermediate_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, test_gen = get_generators(\n",
    "    images_list=imgs_list, \n",
    "    image_dir=IMG_DIR, \n",
    "    image_size=IMG_SIZE, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode='episode_flat', \n",
    "    episode_len=EPIS_LEN, \n",
    "    episode_shift=EPIS_SHIFT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_gen, \n",
    "    output_types=(tf.float32, tf.float32) ,\n",
    "    output_shapes=(tf.TensorShape((BATCH_SIZE* EPIS_LEN, ) + IMG_SIZE), \n",
    "                   tf.TensorShape((BATCH_SIZE* EPIS_LEN, ) + IMG_SIZE)\n",
    "                  )\n",
    ")\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: test_gen,     \n",
    "    output_types=(tf.float32, tf.float32) ,\n",
    "    output_shapes=(tf.TensorShape((BATCH_SIZE* EPIS_LEN, ) + IMG_SIZE), \n",
    "                   tf.TensorShape((BATCH_SIZE* EPIS_LEN, ) + IMG_SIZE)\n",
    "                  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0\n",
    "for data in train_ds:\n",
    "    _instance_scale = float(data[0].numpy().max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_instance_scale=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import Iterable\n",
    "if isinstance(inputs_shape, Iterable):\n",
    "    _outputs_shape = np.prod(inputs_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Layers definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _uf=100\n",
    "# c=16\n",
    "_uf=30\n",
    "# c=(160//4, 210//6, intermediate_dim//2)\n",
    "c=(160//4, 210//6, intermediate_dim//2)\n",
    "menc_lays = [\n",
    "    tf.keras.layers.Conv2D(filters=_uf, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=_uf//5, kernel_size=3, strides=(2, 3), activation='relu'), # _uf*9\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latent_dim)\n",
    "]\n",
    "\n",
    "venc_lays = [\n",
    "    tf.keras.layers.Conv2D(filters=_uf, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=_uf//5, kernel_size=3, strides=(2, 3), activation='relu'), #_uf*9\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latent_dim)\n",
    "]\n",
    "\n",
    "dec_lays = [\n",
    "    tf.keras.layers.Dense(units=np.product(c), activation=tf.nn.relu), # units=_uf*c*c\n",
    "    tf.keras.layers.Reshape(target_shape=c), #target_shape=(c , c, _uf)\n",
    "    tf.keras.layers.Conv2DTranspose(filters=_uf//5, kernel_size=3, strides=(2, 3), padding=\"SAME\", activation='relu'),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=_uf, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    \n",
    "    # No activation\n",
    "    tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=3, strides=(1, 1), padding=\"SAME\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = dataset_name+'Conv_VAE'\n",
    "#windows\n",
    "#recoding_dir='..' + sep_local + '..' + sep_local +'..' + sep_local + '..' + sep_local + '..'+sep_local+'recording'+sep_local + model_name\n",
    "\n",
    "#linux \n",
    "recoding_dir=os.getcwd()+ sep_local  +'recording'+sep_local + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from training.traditional.transformative.VAE import VAE as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'encoder_mean', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latent_dim,\n",
    "        'layers': menc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'encoder_logvar', \n",
    "        'inputs_shape':inputs_shape,\n",
    "        'outputs_shape':latent_dim,\n",
    "        'layers': venc_lays\n",
    "    }\n",
    "\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'generative', \n",
    "        'inputs_shape':latent_dim,\n",
    "        'outputs_shape':inputs_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "from utils.data_and_files.file_utils import create_if_not_exist\n",
    "_restore = os.path.join(recoding_dir, 'var_save_dir')\n",
    "create_if_not_exist(_restore)\n",
    "absolute = abspath(_restore)\n",
    "print(\"Restore_dir\",absolute)\n",
    "absolute = abspath(recoding_dir)\n",
    "print(\"Recording_dir\",absolute)\n",
    "print(\"Current working dir\",os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae = AE( \n",
    "    name=model_name,\n",
    "    inputs_shape=inputs_shape,\n",
    "    outputs_shape=inputs_shape,\n",
    "    latent_dim=latent_dim,\n",
    "    batch_size=BATCH_SIZE* EPIS_LEN,\n",
    "    variables_params=variables_params, \n",
    "    filepath=None #to restore trained model, set filepath=_restore\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added for linux warning suppression\n",
    "import logging\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING)\n",
    "\n",
    "from training.callbacks.progress_bar import NotebookPrograssBar\n",
    "from training.callbacks.sample_generation import SampleGeneration\n",
    "from training.callbacks.save_model import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progbar = NotebookPrograssBar(leave_outer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=1e-12, \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSaver(filepath=_restore,save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.join(recoding_dir, 'csv_dir')\n",
    "create_if_not_exist(csv_dir)\n",
    "csv_dir = os.path.join(csv_dir, model_name+'.csv')\n",
    "csv_log = tf.keras.callbacks.CSVLogger(csv_dir, append=True)\n",
    "absolute = abspath(csv_dir)\n",
    "print(\"Csv_dir\",absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_dir = os.path.join(recoding_dir, 'image_gen_dir')\n",
    "create_if_not_exist(image_gen_dir)\n",
    "absolute = abspath(image_gen_dir)\n",
    "print(\"Image_gen_dir\",absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SampleGeneration(latent_shape=latent_dim, filepath=image_gen_dir, gen_freq=5, save_img=True, gray_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae.fit(\n",
    "    x=train_ds,\n",
    "    input_kw=None,\n",
    "    steps_per_epoch=50,\n",
    "    epochs=int(1e6), \n",
    "    verbose=0,\n",
    "    callbacks=[progbar, es, ms, csv_log, sg],\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_ds:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt0 = batch[0][:10]\n",
    "xt1 = batch[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt0 = tf.concat([x for x in xt0], axis=1)\n",
    "xt1 = tf.concat([x for x in xt1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt1_pred = ae.predict(batch[0][:10])\n",
    "xt1_pred = tf.concat([x for x in xt1_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 80), dpi=300)\n",
    "plt.axis('off')\n",
    "print('input')\n",
    "plt.imshow(xt0)\n",
    "#plt.save()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 80), dpi=300)\n",
    "plt.axis('off')\n",
    "print('output')\n",
    "plt.imshow(xt1)\n",
    "#plt.save()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 80), dpi=300)\n",
    "plt.axis('off')\n",
    "print('prediction')\n",
    "plt.imshow(xt1_pred)\n",
    "#plt.save()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
