{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from training.generators.FileImageGenerator import create_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '..\\\\data\\\\atari_v1\\\\screens\\\\mspacman'\n",
    "validation_percentage = 25\n",
    "valid_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image directory ..\\data\\atari_v1\\screens\\mspacman not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9fe628e3d8ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mimage_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_pct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_percentage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mvalid_imgae_formats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mC:\\Git\\test_run\\Generative_Models\\training\\generators\\FileImageGenerator.py\u001b[0m in \u001b[0;36mcreate_image_lists\u001b[1;34m(image_dir, validation_pct, valid_imgae_formats, max_num_images_per_class)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image directory {} not found.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mimage_lists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0msub_dirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Image directory ..\\data\\atari_v1\\screens\\mspacman not found."
     ]
    }
   ],
   "source": [
    "imgs_list = create_image_lists(\n",
    "    image_dir=images_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(160, 210, 3)\n",
    "batch_size = 5\n",
    "EPIS_LEN = 6\n",
    "EPIS_SHIFT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator, testing_generator = get_generators(\n",
    "    images_list=imgs_list, \n",
    "    image_dir=images_dir, \n",
    "    image_size=image_size, \n",
    "    batch_size=batch_size, \n",
    "    class_mode='episode', \n",
    "    episode_len=EPIS_LEN, \n",
    "    episode_shift=EPIS_SHIFT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: training_generator, \n",
    "    output_types=(tf.float32, tf.float32) ,\n",
    "    output_shapes=(tf.TensorShape((batch_size, EPIS_LEN, ) + image_size), \n",
    "                   tf.TensorShape((batch_size, EPIS_LEN, ) + image_size)\n",
    "                  )\n",
    ")\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: testing_generator,     \n",
    "    output_types=(tf.float32, tf.float32) ,\n",
    "    output_shapes=(tf.TensorShape((batch_size, EPIS_LEN, ) + image_size), \n",
    "                   tf.TensorShape((batch_size, EPIS_LEN, ) + image_size)\n",
    "                  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'atari_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dim = 50\n",
    "input_shape= (EPIS_LEN, )+image_size # image shape\n",
    "latents_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdConv = lambda **kwds: tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(**kwds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdDeConv = lambda **kwds: tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2DTranspose(**kwds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdDense = lambda **kwds: tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(**kwds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_mean_lays = [\n",
    "    tdConv(filters=c, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tdConv(filters=2*c, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latents_dim)\n",
    "]\n",
    "\n",
    "enc_var_lays = [\n",
    "    tdConv(filters=c, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tdConv(filters=2*c, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # No activation\n",
    "    tf.keras.layers.Dense(latents_dim)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "dec_lays = [\n",
    "    tf.keras.layers.Dense(units=c**3, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Reshape(target_shape=(1, c, c, c)),\n",
    "    tdDeConv(filters=2*c, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    tdDeConv(filters=c, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation='relu'),\n",
    "    \n",
    "    # No activation\n",
    "    tdDeConv(filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\"),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Atari_VAE_tconv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_dir='..\\\\experiments\\\\'+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.join(experiments_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.autoencoders_conditional.Cond_VAE import CondVAE as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_params = \\\n",
    "[\n",
    "    {\n",
    "        'name': 'inference_mean', \n",
    "        'input_shape':input_shape,\n",
    "        'output_shape':latents_dim,\n",
    "        'layers': enc_mean_lays\n",
    "    }\n",
    "    ,\n",
    "    \n",
    "     {\n",
    "        'name': 'inference_logvariance', \n",
    "        'input_shape':input_shape,\n",
    "        'output_shape':latents_dim,\n",
    "        'layers':enc_var_lays\n",
    "    }\n",
    "    ,\n",
    "    \n",
    "        {\n",
    "        'name': 'decoder', \n",
    "        'input_shape':latents_dim,\n",
    "        'output_shape':input_shape,\n",
    "        'layers':dec_lays\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore = os.path.join(experiments_dir, 'var_save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AE( \n",
    "    model_name=model_name, \n",
    "    input_shape=input_shape, \n",
    "    latents_dim=latents_dim, \n",
    "    variables_params=variables_params, \n",
    "    restore=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_generated = 36\n",
    "#random_latents = np.random.normal(size=[n_generated, latents_dim])\n",
    "#np.save(file='random_latents.npy', arr=random_latents)\n",
    "#random_latents = tf.constant(np.load(file='..\\\\data\\\\random_latents.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latents = tf.constant(np.random.normal(size=[n_generated, latents_dim]))\n",
    "random_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae.fit(\n",
    "    train_dataset=train_ds, \n",
    "    test_dataset=test_ds,\n",
    "    instance_name='episode',\n",
    "    instance_scale=1,\n",
    "    epochs=10,\n",
    "    learning_rate=1e-3,\n",
    "    random_latents=random_latents,\n",
    "    latents_dim=latents_dim ,\n",
    "    experiments_dir=experiments_dir,\n",
    "    gray_plot=True,\n",
    "    generate_epoch=5,\n",
    "    save_epoch=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
