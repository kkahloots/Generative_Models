import numpy as np
import tensorflow as tf
from evaluation.shared import log10

def sharpdiff(inputs, x_logits):
    """
    Computes the Sharpness Difference error between the generated images and the ground truth
    images.

    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the
                       generator model.
    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for
                      each frame in gen_frames.

    @return: A scalar tensor. The Sharpness Difference error over each frame in the batch.
    """
    gen_frames = tf.sigmoid(x_logits)
    gt_frames = inputs

    shape = gen_frames.shape
    if len(shape) > 4:
        num_pixels = tf.cast(x=shape[2] * shape[3] * shape[4], dtype='float')
        if shape[4] == 1:
            gen_frames = tf.image.grayscale_to_rgb(gen_frames)
            gt_frames = tf.image.grayscale_to_rgb(gt_frames)

            shape = tf.shape(gen_frames)
            num_pixels = tf.cast(x=shape[2] * shape[3] * shape[4], dtype='float')

    else:
        num_pixels = tf.cast(x=shape[1] * shape[2] * shape[3], dtype='float')
        if shape[3] == 1:
            gen_frames = tf.image.grayscale_to_rgb(gen_frames)
            gt_frames = tf.image.grayscale_to_rgb(gt_frames)

            shape = tf.shape(gen_frames)
            num_pixels = tf.cast(x=shape[1] * shape[2] * shape[3], dtype='float')

    # gradient difference
    # create filters [-1, 1] and [[1],[-1]] for diffing to the left and down respectively.
    # Could this be simplified with one filter [[-1, 2], [0, -1]]?
    pos = tf.constant(np.identity(3), dtype=tf.float32)
    neg = -1 * pos
    filter_x = tf.expand_dims(tf.stack([neg, pos]), 0)  # [-1, 1]
    filter_y = tf.stack([tf.expand_dims(pos, 0), tf.expand_dims(neg, 0)])  # [[1],[-1]]
    strides = [1, 1, 1, 1]  # stride of (1, 1)
    padding = 'SAME'

    if len(shape) > 4:
        convx = lambda tensor: tf.abs(tf.nn.conv2d(tensor, filter_x, strides, padding=padding))
        convy = lambda tensor: tf.abs(tf.nn.conv2d(tensor, filter_y, strides, padding=padding))

        gen_dx = tf.reduce_sum(tf.map_fn(convx, gen_frames), axis=1)
        gen_dy = tf.reduce_sum(tf.map_fn(convy, gen_frames), axis = 1)

        gt_dx = tf.reduce_sum(tf.map_fn(convx, gt_frames), axis=1)
        gt_dy = tf.reduce_sum(tf.map_fn(convy, gt_frames), axis=1)


    else:
        gen_dx = tf.abs(tf.nn.conv2d(gen_frames, filter_x, strides, padding=padding))
        gen_dy = tf.abs(tf.nn.conv2d(gen_frames, filter_y, strides, padding=padding))
        gt_dx = tf.abs(tf.nn.conv2d(gt_frames, filter_x, strides, padding=padding))
        gt_dy = tf.abs(tf.nn.conv2d(gt_frames, filter_y, strides, padding=padding))

    gen_grad_sum = gen_dx + gen_dy
    gt_grad_sum = gt_dx + gt_dy

    grad_diff = tf.abs(gt_grad_sum - gen_grad_sum)

    batch_errors = 10 * log10(1 / ((1 / num_pixels) * tf.reduce_sum(grad_diff, [1, 2, 3])))
    return tf.reduce_mean(batch_errors)
